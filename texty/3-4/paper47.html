<html>

<!-- Mirrored from informationr.net/ir/3-4/paper47.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:27 GMT -->
<head>
<link rel="stylesheet" href="../IRstyle.css">
<title>Human creation of abstracts with selected computer assistance tools</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="keywords" content="TEXNET, abstracting, software, computer assistance, abstracts">
<meta name="description" content="After introductory training, a research assistant used the TEXNET abstracting assistance software to create abstracts to articles available via the World Wide Web. The assistant also compiled introductory documentation, including a guide to abstracting using computer assistance tools. This article discusses problems encountered, tools selected for preferred use, and implications for future software development.">
<meta name="VW96.objecttype" content="Document">
<meta name="ROBOTS" content="ALL">
<meta name="DC.Title" content="Human creation of abstracts with selected computer assistance tools">
<meta name="DC.Creator" content="Timothy C. Craven">
<meta name="DC.Subject" content="TEXNET, abstracting, software, computer assistance, abstracts">
<meta name="DC.Description" content="After introductory training, a research assistant used the TEXNET abstracting assistance software to create abstracts to articles available via the World Wide Web. The assistant also compiled introductory documentation, including a guide to abstracting using computer assistance tools. This article discusses problems encountered, tools selected for preferred use, and implications for future software development.">
<meta name="DC.Publisher" content="Professor T.D. Wilson">
<meta name="DC.Coverage.PlaceName" content="Global">
<script language="JavaScript" type="text/JavaScript">
<!--
function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.length,a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_nbGroup(event, grpName) { //v6.0
  var i,img,nbArr,args=MM_nbGroup.arguments;
  if (event == "init" && args.length > 2) {
    if ((img = MM_findObj(args[2])) != null && !img.MM_init) {
      img.MM_init = true; img.MM_up = args[3]; img.MM_dn = img.src;
      if ((nbArr = document[grpName]) == null) nbArr = document[grpName] = new Array();
      nbArr[nbArr.length] = img;
      for (i=4; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
        if (!img.MM_up) img.MM_up = img.src;
        img.src = img.MM_dn = args[i+1];
        nbArr[nbArr.length] = img;
    } }
  } else if (event == "over") {
    document.MM_nbOver = nbArr = new Array();
    for (i=1; i < args.length-1; i+=3) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = (img.MM_dn && args[i+2]) ? args[i+2] : ((args[i+1])? args[i+1] : img.MM_up);
      nbArr[nbArr.length] = img;
    }
  } else if (event == "out" ) {
    for (i=0; i < document.MM_nbOver.length; i++) {
      img = document.MM_nbOver[i]; img.src = (img.MM_dn) ? img.MM_dn : img.MM_up; }
  } else if (event == "down") {
    nbArr = document[grpName];
    if (nbArr)
      for (i=0; i < nbArr.length; i++) { img=nbArr[i]; img.src = img.MM_up; img.MM_dn = 0; }
    document[grpName] = nbArr = new Array();
    for (i=2; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = img.MM_dn = (args[i+1])? args[i+1] : img.MM_up;
      nbArr[nbArr.length] = img;
  } }
}
//-->
</script>

</head>
<body bgcolor="#ffffff" onLoad="MM_preloadImages('../figs/iauthori1.gif','../figs/isubji1.gif','../figs/isearch1.gif','../figs/ihome1.gif','../figs/contents1.gif')">
<table align="center" border="0" cellpadding="0" cellspacing="0">
<tr><td height="30" align="center" colspan="5"><h4>Information Research, Vol. 3  No. 4, April 1998</h4></td></tr>
  <tr> 
    <td><a href="infres34.html" target="_top" onClick="MM_nbGroup('down','group1','contents','',1)" onMouseOver="MM_nbGroup('over','contents','../figs/contents1.gif','',1)" onMouseOut="MM_nbGroup('out')"><img name="contents" src="../figs/contents.gif" border="0" alt="" onLoad=""></a></td>
    <td><a href="../iraindex.html" target="_top" onClick="MM_nbGroup('down','group1','authorindex','',1)" onMouseOver="MM_nbGroup('over','authorindex','../figs/iauthori1.gif','',1)" onMouseOut="MM_nbGroup('out')"><img src="../figs/iauthori.gif" alt="" name="authorindex" width="120" height="20" border="0" onload=""></a></td>
    <td><a href="../irsindex.html" target="_top" onClick="MM_nbGroup('down','group1','subjindex','',1)" onMouseOver="MM_nbGroup('over','subjindex','../figs/isubji1.gif','',1)" onMouseOut="MM_nbGroup('out')"><img src="../figs/isubji.gif" alt="" name="subjindex" width="120" height="20" border="0" onload=""></a></td>
    <td><a href="../search.html" target="_top" onClick="MM_nbGroup('down','group1','search','',1)" onMouseOver="MM_nbGroup('over','search','../figs/isearch1.gif','',1)" onMouseOut="MM_nbGroup('out')"><img src="../figs/isearch.gif" alt="" name="search" width="120" height="20" border="0" onload=""></a></td>
    <td><a href="../index.html" target="_top" onClick="MM_nbGroup('down','group1','home','',1)" onMouseOver="MM_nbGroup('over','home','../figs/ihome1.gif','',1)" onMouseOut="MM_nbGroup('out')"><img name="home" src="../figs/ihome.gif" border="0" alt="" onLoad=""></a></td>
  </tr>
</table>
<hr color=#ff00ff size=3>


<h1>Human creation of abstracts with selected computer assistance tools</h1>

<h4><a href="mailto:t.craven@uwo.ca">Timothy C. Craven</a><br>
Faculty of Communications and Open Learning,<br>
The University of Western Ontario,<br>
London, Ontario N6G 1H1<br>
Canada</h4>
<br>

<div>Abstract</div>
<blockquote>
After introductory training, a research assistant used the TEXNET abstracting assistance software to create abstracts to articles available via the World Wide Web. The assistant also compiled introductory documentation, including a guide to abstracting using computer assistance tools. This article discusses problems encountered, tools selected for preferred use, and implications for future software development.</blockquote>
<br><br>

<h2>Introduction</h2>
<p>Suggestions for purely automatic abstracting methods,
as surveyed by Paice (<a href="#PAICE1990">1990</a>)
and Endres-Niggemeyer (<a href="#ENDRE1994">1994</a>),
do not show immediate promise of totally superseding human effort.
An appropriate short-term goal would seem to be a hybrid system,
in which some tasks are performed by human abstractors
and other tasks by software. The model of such hybrid abstracting with which this paper is concerned
involves providing writers of conventional abstracts with various
computerized tools to assist them. </p>

<p> The general aim of the research
reported in part in this paper is the development of a prototype
computerized abstractor's assistant. As a kind of writer's assistant, such
a software package should encompass a simple word processor and other
general writer's tools (<a href="#KOZMA1991">Kozma, 1991</a>). In addition,
the package should integrate tools, such as an automatic extractor, related
specifically to the task of abstracting. Abstracting assistance features
are being prototyped in a text network management system, known as TEXNET
(<a href="#CRAVE1988">Craven, 1988</a>) (<a href="#CRAVE1991B">Craven,
1991b</a>). </p>

<p> Little other research has been reported on the development
of computerized abstractor's assistance packages. By contrast, there exists
a wide range of assistance packages for indexers, including such commercial
products as CINDEX (<a href="#INDEX1997">Indexing Research, 1997</a>),
MACREX (<a href="#CALVE1998">Calvert, 1998</a>), and SKY Index (<a
href="#SKY1998">SKY Software, 1998</a>). Some specialized applications,
such as that developed for the American Petroleum Institute (<a
href="#MARTI1987">Martinez, Lucey, and Linder, 1987</a>), analyze free text
and suggest suitable controlled-vocabulary index terms. <p> Among other
purposes, TEXNET is designed to allow abstracting of Web pages. It does
not, however, include a Web browser. Rather than reinventing the wheel, it
has been decided to modify TEXNET to work as a companion program to
Netscape Navigator or other compatible Web-browsing software. A similar
approach is exemplified by WEBNET, a companion program for the the WWW
browser, that provides a graphic display interface mapping areas of the Web
visited (<a href="#COCKB1996">Cockburn &amp; Jones, 1996</a>).  </p>

<p> When
properly configured, TEXNET can capture HTML pages from a compatible viewer
and translate them into its own format, automatically assigning weights to
text segments in the process. The user invokes the capture and translation
by clicking on a button that is controlled by TEXNET but that floats on top
of other application windows, including the browser. <p> Should
compatibility problems arise with the browser, another option is available:
TEXNET allows translation of any HTML code stored on the Windows clipboard,
via a &quot;Filter Clipboard&quot; function. <p> How the various HTML tags
are translated and what weights are associated with text tagged in various
ways are controlled by a set of filters. These filters have default values
and can also be edited by the user. <p> One method of testing the value of
the TEXNET tools, or any tools for assisting in the writing of abstracts,
is formal experimentation. In an ongoing series of experiments (<a
href="#CRAVE1996">Craven, 1996</a>), subjects have been asked to write
abstracts of an article using a modified version of TEXNET from which many
features have been omitted. Features that are included, and on which the
experiments have focused, are automatically generated displays of keywords
or phrases. </p>

<p> Of these two displays, that of keywords was the first to be
developed, for two main reasons. First, an earlier study (<a
href="#CRAVE1991A">Craven, 1991a</a>) had showed little use in abstracts of
longer verbatim word sequences from full texts. Second, keyword extraction
is a somewhat simpler task than phrase extraction, though methods for
efficient phrase extraction do exist, as in INDEX (<a
href="#JONES1990">Jones <i>et al.</i>, 1990</a>), FASIT (<a
href="#BURGI1992">Burgin &amp; Dillon, 1992</a>), CLARIT (<a
href="#PAIJM1993">Paijmans, 1993</a>), and work reported by Fagan (<a
href="#FAGAN1989">1989</a>). The key phrase display was developed later (<a
href="#CRAVEINPR">Craven, in press</a>). A special feature of this display
has been the use of a compact form that takes account of overlaps among the
phrases. <p> Results of the experiment have showed considerable variation
among subjects, but slightly fewer than half of those presented with the
phrase display have found it &quot;quite&quot; or &quot;very&quot; useful
in writing their abstracts. </p>

<p> The experimental situation has had clear
limitations. Subjects have had a very limited amount of time to become
familiar with the features of the abstracting assistance tools. To allow
any familiarity within the time available, they have been given access to
only a very limited set of tools. Their previous experience with
abstracting may have been scanty or nonexistent. The source texts, while
selected so as not to be excessively esoteric, may have been in unfamiliar
areas. <p> Accordingly, a different, more extended kind of evaluation and
testing of the current state of TEXNET was called for, which, it was hoped,
would serve in part to complement the experimental results. The emphasis
would be on the package and its features, rather than on the human users.</p>

<h2>Tasks of the research assistant</h2>

<p>A student on a co-operative work/study programme was hired as a full-time research assistant
for a period of four months.
The research assistant had a number of tasks,
to be undertaken in consultation with the researcher:</p>

<ol>
<li>to become familiar with the main features of TEXNET;</li>
<li>using TEXNET to practice writing abstracts of documents available in HTML format
on the World Wide Web;</li>
<li>to identify bugs or other problems with using the software in practice;</li>
<li>to note which tools or combinations of tools appeared most useful in
abstract writing; and </li>
<li>to prepare documentation for TEXNET.</li></ol> 

<p> The assistant, who had received a little previous instruction in abstracting
and was broadly familiar with the guidelines of the then ANSI standard on
abstracting (<a href="#ANSI1979">ANSI, 1979</a>) (since superseded by a new
edition: <a href="#NISO1997">NISO, 1997</a>), began work by reading about
25 papers written by the researcher and others on computerized abstracting
and on tools for abstractors, and then, as the work period progressed,
consulted Cremmins' standard work on abstracting (<a
href="#CREMM1996">Cremmins, 1996</a>). In general, the abstracts produced
were not evaluated at the time by the researcher; but feedback on the
general form considered suitable was provided at about the 6-week point. No
exact maximum abstract length was required. </p>

<p> Choice of the specific
material abstracted was left up to the assistant. Nevertheless, it was
required to be papers or articles, as opposed to other formats that might
be encountered on the Web, such as tables of contents, excerpts, or
abstracts; it was also not to be too specialized to be readily understood.
<p> A commercial spell checker (Winspell: <a href="#R_TH1994">R&amp;TH,
1994</a>) was made available as a companion program to TEXNET for the
assistant's use. This package is capable of monitoring text as it is typed
into a window and signalling the user if a word typed appears to be
misspelled. Several participants in the experiments had commented on the
desirability of spell checking as an assistance feature. </p>

<p> Over the years
of its development, TEXNET has acquired a wide variety of features, some
easier to learn and use than others. It was decided that the assistant
should not explore in detail, or receive much training in, a number of the
less likely useful or more difficult features of the package. Generally,
these same features were also omitted from the documentation produced, or
not dealt with in much detail. </p>

<p> Features to which the assistant paid
especial attention included the following:</p> 

<ul> 
<li>importation of Web documents </li>
<li>displaying and editing of source texts and abstracts</li>
<li>extracting of text segments based on Boolean queries, on any matches to keywords from a given list, or on segment weights  </li>
<li>weighting of text segments by occurrences of frequent keywords or of keywords from selected
passages </li>
<li>frequent keyword and key phrase displays </li>
</ul> 

<p> Features not emphasized included the following: </p> 

<ul> 
<li>manual or automatic structuring of source texts with links that reflect dependency of one
passage on another, contextual passage for its meaning </li>
<li>database functions, which were designed to work with structured texts </li>
<li>features requiring a lot of time to develop ancillary data to support their
effective use, including a thesaurus and lists of positive and negative cue
words and of general indicative formulas or phrases commonly used in
abstracting. </li>
</ul>

<h2>Results</h2>

<p>As a first set of texts to be abstracted,the assistant chose 30 documents from Seeker1's Cyber Anthology Home Page (then available at http://www.cla.ufl.edu/anthro/cyberanthro/newhome.html - <strong><em>[no longer available, December 2002]</em></strong>). These covered various aspects of human-computer relationships, from cyberpsychology to technoshamanism. Later, abstracting work was performed on 10 documents from Sarah Zupko's <a href="http://www.popcultures.com/">Cultural Studies Center</a> Web site (then available at  http://www.msc.net/~zupko/articles/national.html, now (<strong><em>December 2002</em></strong>) at http://www.popcultures.com/.</p>

<p>Actual draft abstracts were produced for twenty-four of the documents in the first set. Interesting from the point of view of future abstracting tool design are the other elements that the assistant decided to store in what would normally be files for the abstracts alone:</p>

<ul>
<li>notes (about ten files),</li>
<li>longer extracts (about nineteen),</li>
<li>keyword lists (about fifteen),</li>
<li>phrase lists (about fourteen),</li>
<li>definitions (about four),</li>
<li>and segment weights.</li>
</ul>

<p>A few technical difficulties were naturally encountered. Some of these led to minor corrections of the software, either during the period of the assistant's employment or later.  Others related to specific peculiarities of the hardware or the operating environment used. Those interested may obtain further details <a href="mailto:t.craven@uwo.ca">from the author</a>.</p>

<p>Initially, the assistant found the displays of frequent keywords not to be particularly useful.
The phrase displays seemed of much more value, giving such terms as &quot;think tanks&quot;,
&quot;pr firms&quot;, and &quot;right wing&quot;. Somewhat later, however, the small number of substantial phrases in the phrase displays was remarked upon.</p>

<p>The phrase display format was not found to be perfectly self-explanatory: the role of the semicolon (&quot;;&quot;) in marking phrase boundaries needed to be explained by the researcher, as did the fact that a phrase might consist of only one word. The original seven word limit on phrase length was later increased to ten, but it might have been desirable to be able to accommodate still longer sequences such as the 12-word &quot;and meant to be played by two refined men in a civilized&quot;. </p>

<p> Another respect in which the phrase display was obscure was in the rules followed in deriving it. These had not been explained in the existing help files for the package. In addition, the assistant had already had some exposure to software that extracted phrases in a different manner, based on phrase frequency alone rather than a combination of phrase frequency with word significance. </p>

<p> Certain properties of the source text could degrade the phrase display. For example, a number of repetitions of identical citations in one article led to the phrase list's being almost swamped with sequences such as &quot;Baudrillard 1975&quot;. </p>

<p> Both the phrase display and the frequent keyword display were often cut off at the 100-node threshold (with one node for each word and each phrase boundary). This problem could largely be avoided by the assistant's increasing the default minimum number of occurrences for a word to be considered &quot;frequent&quot; in the text. The package was subsequently modified to provide more compact displays with a much higher limit. </p>

<p> At the seven-week mark, the assistant proposed the
following as the ideal preliminaries to writing an abstract: read the
article; &quot;structure&quot; the text (simply in order to make the text
segments generally shorter); call up the frequent keywords display; record
selected keyword pairs that seem to represent important concepts; return to
the unstructured text (which has normally longer text segments); use the
Boolean extract function to view an extract based on each of the keyword
pairs previously selected. Some specific personal names, titles of books,
and the like might still need to be picked up from elsewhere in the source
text. It was also acknowledged that longer, more complicated texts might
require a different approach. </p>

<p> By contrast with the frequent keyword
display, the automatic manipulation of segment length by switching between
structured and unstructured formats did not appear to have much influence
on the phrase display. </p>

<p> Manual manipulation of segment breaks was also
found useful in improving the quality of extraction. </p>

<p> The file format
for the documentation had not been decided on definitely in advance. After
the assistant's first draft was ready, it was clear that the material would
be best presented as a hypertext and that illustrations would need to be
incorporated. The format decided upon was HTML, on two main grounds:
creation of Windows Help files with available tools had proven immensely
difficult in earlier experimentation; and it was expected that almost all
users would have access to an HTML viewer. Use of HTML would also enable
the documentation to be viewed by interested parties on platforms that were
not Windows-based, even if they could not actually run the software.</p>

<h2>Discussion</h2>

<p>In dealing with materials on the World Wide Web, it has been found that inverse document frequency scores of terms are not stable (<a href="#SRINI1996">Srinivasan, Ruiz, Lam, 1996</a>). This finding serves as a reminder that stop lists, such as that used in TEXNET, cannot be universal and may indeed need to be modified over time even for the same type of material. As it was, the assistant was given the default TEXNET stop list and was not asked to develop it further. Thus, the feature of TEXNET that allows for stop list variation was not tested in this research.</p>

<p>Development of a set of phrases commonly used in abstracts was also not one of the tasks required of the assistant. Like a stop list, such a phrase list should probably vary with the field, as suggested by Tibbo's (<a href="#TIBBO1992">1992</a>) observation of considerable variation in abstract content types between disciplines.</p>

<p>Compared to social science literature, texts in the hard sciences tend to have more domain-specific terms, and more of these tend to occur in sequences (<a href="#HAAS1997">Haas, 1997</a>). This difference might contribute to readier automatic extraction of useful specific indexing terms from hard science texts. Word sequences that might be useful in abstracting, however, as noted elsewhere (<a href="#CRAVEINPR">Craven, in press</a>), are not limited to phrases resembling indexing terms, still less to terms that are specific to particular disciplines. Word sequences automatically extracted from the documents examined by the assistant included &quot;information wants to be free&quot; and &quot;if you want to see the future&quot;; scarcely suitable as index terms, these clauses nevertheless tell a great deal about the content of the articles from which they were extracted and might even be included in the abstracts.</p>

<p>The switching between structured and unstructured formats suggested by the assistant
was later rendered unnecessary by a modification of the word frequency computation method:
multiple occurrences of a word within a segment are now counted separately.</p>

<p>In response to comments made by earlier research subjects, an optional dynamic word-count display had been introduced into the full package, for both abstract and full text.
The assistant did not mention this feature in any of the documentation prepared.
Two factors may be at work here in the way that the assistant was working in contrast to the experimental situation: the source texts had already been filtered to some extent for length
by the assistant, and no strong time or space constraints had been imposed.</p>

<p>For a variety of reasons, it does not seem desirable to lock the abstractor out of manipulations of the source text, though a copy of the original should normally be retained in a backup file.
Examples noted where temporary modification of the source might be useful
include the following: adding or deletion of segment breaks to improve the
quality of the automatic extracts; tidying up of anomalies arising in
translation from HTML; and deletion of material, such as citations, that
may detract from the quality of frequent keyword and phrase displays, as
well as from some of the weighting functions.</p>

<h2>Further research</h2>

<p>The default minimum number of occurrences for a word to be considered &quot;frequent&quot;
was initially determined for shorter documents than those used in this study. Automatic resetting of this value when a source text is loaded has now been added to the package.
The reset value is currently based simply on the number of lines in the document. There are other variables that might be taken into account in the calculation: the number of words,
though this would tend to be highly correlated with the number of lines; the proportion of stop words, since occurrences of these would not be counted; and the repetition of vocabulary in the text, since high repetitiveness could result in too many words being &quot;frequent&quot;.
As has long been recognized, different texts show different degrees of concentration, or repetition, of vocabulary. For example, vocabulary has been observed to be more concentrated in theoretical than in practice-oriented material (<a href="#LOSEE1996">Losee, 1996</a>).</p>

<p>Making available a database of source texts and abstracts seems likely to prove beneficial from several points of view. Directly, abstractors can, for instance, check previous work by themselves or other abstractors or identify more readily the distinguishing features of the document at hand. The software could make use of keyword occurrence counts, dynamically
updated, to pinpoint more accurately which words, and hence which phrases, are more likely significant in a given document. Given a sufficient collection of well written abstracts, it might even be possible to begin to suggest suitable phrasing for the abstract of a newly added document based on past correlations.</p>

<p> As the number and length of phrases extracted increases, especially with longer source texts, so does the need to organize them in a way more useful than mere alphabetical order. Some of the participants in the experiments have already suggested an ordering that reflects the order of ideas in the original or that suggested for the abstract itself. Some preliminary research is under way to investigate the feasibility of achieving this end by simple automatic means.</p>

<p> The assistant's decision to commandeer the abstract files to hold a variety of other useful data about the texts abstracted suggests a strong need that should be met more formally. It should be made easy for the abstractor to store data such as notes, lists of keywords and phrases, extracts, and definitions for an abstracted text. These elements might be assigned either to separate files or to fields within a single file or abstracting record. <p> As noted by Nielsen (<a href="#NIELS1994">1994</a>), a relatively small number of testers is sufficient for identifying the majority of defects in a software package. It is almost certain, however, that defects do remain in the TEXNET package.</p>

<p> The preferences of one student abstractor cannot necessarily be generalized to all other abstractors. Indeed, in studies involving think-aloud protocols (<a href="#ENDRE1991">Endres-Niggemeyer, Waumans, &amp; Yamashita, 1991</a>), it has been noted that individuals use quite different approaches in writing abstracts. This variability of approaches has also been noted in the TEXNET experimental sessions. One question that might thus be addressed is the extent to which other abstract writers find the suggestions in the documentation useful in their abstracting. <p> To this end, and to provide opportunities for independent evaluation of the TEXNET tools, both the software and the documentation are being made freely available to students and other interested individuals.</p>

<h2>Availability</h2>

The TEXNET software referred to in this paper, as well as the simplified version used in the experiments, is written as a Microsoft Windows application in Borland Pascal with Objects 7.0.
Either source or executable code is available by sending a 3 1/2&quot; dual-density diskette to the author: both may be obtained if two dual-density or one high-density diskette is
sent. An executable version of TEXNET may also be downloaded in a ZIP file from the Web site <a
href="http://netlib.slis.uwo.ca/">netlib.slis.uwo.ca</a>.

<h2>Acknowledgement</h2>

<p>Research reported in this paper was supported in part by individual operating grant A9228
of the Natural Sciences and Engineering Research Council of Canada.</p>

<h2>References</h2>
<p>
<a name="ANSI1979">American National Standards Institute (1979)</a>
<i>American National Standard for Writing Abstracts</i>
(ANSI Z39.14-1979).
<p>
<a name="BURGI1992">Burgin, R. and Dillon, M. (1992)</a>
&QUOT;Improving disambiguation in FASIT.&QUOT;
<i>Journal of the American Society for Information Science</i>,
<b>43</b> (2), 101-114. 
<p>
<a name="CALVE1998">Calvert, D. and Calvert, H. (1998)</a>
&QUOT;MACREX HOME PAGE.&QUOT;
(<a href="http://www.macrex.cix.co.uk/"
>http://www.macrex.cix.co.uk/</a>,
visited 1998 March 5)
<p>
<a name="COCKB1996">Cockburn, A. and Jones, S. (1996)</a>
&QUOT;Which way now?
Analyzing and easing inadequacies in WWW navigation.&QUOT;
<i>International Journal of Human-Computer Studies</i>,
<b>45</b> (1), 105-129. 
<p>
<a name="CRAVE1988">Craven, T.C. (1988)</a>
&QUOT;Text network display editing with special reference to the production of customized abstracts,&QUOT; <i>Canadian Journal of Information Science</i>, <b>13</b> (1/2), p.59-68.

<p> <a name="CRAVE1991A">Craven, T.C. (1991a)</a> &QUOT;Use of words and
phrases from full text in abstracts&QUOT;, <i>Journal of Information
Science</i>, <b>16</b>, 351-358.

<p> <a name="CRAVE1991B">Craven, T.C. (1991b)</a> &QUOT;Algorithms for graphic display of sentence dependency structures&QUOT;, <i>Information Processing and Management</i>, <b>27</b>
(6), 603-613.

<p> <a name="CRAVE1993A">Craven, T.C. (1993)</a> &QUOT;A computer-aided abstracting tool kit&QUOT;, <i>Canadian Journal of Information Science</i>, <b>18</b> (2), 19-31.

<p> <a name="CRAVE1996">Craven, T.C. (1996)</a> &QUOT;An experiment in the use of
tools for computer-assisted abstracting&QUOT;, <i>in: ASIS '96: proceedings
of the 59th ASIS Annual Meeting 1996, volume 33), Baltimore, Maryland,
October 21-24, 1996</i>, edited by S. Hardin. Medford, New Jersey:
Information Today. pp.203-208.

<p> <a name="CRAVEINPR">Craven, T.C. (in press)</a> &QUOT;Presentation of repeated phrases in a computer-assisted abstracting tool kit.&QUOT; <i>Information Processing and Management</i>.

<p> <a name="CREMM1996">Cremmins, E.T. (1996)</a> <i>Art of Abstracting</i>, 2nd Edition. Arlington, Va.: Information Resources Press.

<p> <a name="ENDRE1994">Endres-Niggemeyer, B. (1994)</a> &QUOT;Summarizing
text for intelligent communication: results of the Dagstuhl Seminar.&QUOT;
<i>Knowledge Organization</i>, <b>21</b> (4), 213-223.

<p> <a name="ENDRE1991">Endres-Niggemeyer, B.; Waumans, W.; Yamashita, H.
(1991)</a> &QUOT;Modelling summary writing by introspection: a small-scale
demonstrative study.&QUOT; <i>Text</i>, <b>11</b> (4), 523-552.

<p> <a name="FAGAN1989">Fagan, J.L. (1989)</a> &QUOT;The effectiveness of a
nonsyntactic approach to automatic phrase indexing for document
retrieval.&QUOT; <i>Journal of the American Society for Information
Science</i>, <b>40</b> (2), 115-132.

<p> <a name="HAAS1997">Haas, S.W. (1997)</a> &QUOT;Disciplinary varieties in automatic sublanguage term identification.&QUOT; <i>Journal of the American Society for Information
Science</i>, <b>48</b> (1), 67-79.

<p> <a name="INDEX1997">Indexing Research (1997)</a> &QUOT;Indexing Research: CINDEX&quot;. (<a
href="http://www.indexres.com/cindex.html" >http://www.indexres.com/cindex.html</a>, visited 1998 March 5)

<p> <a name="JONES1990">Jones, L.P.; Gassie, E.W.; Radhakrishnan, S. (1990)</a>
&QUOT;INDEX: the statistical basis for an automatic conceptual
phrase-indexing system.&QUOT; <i>Journal of the American Society for
Information Science</i>, <b>41</b> (2), 87-97.

<p> <a name="KOZMA1991">Kozma, R.B. (1991)</a> &QUOT;The impact of computer-based
tools and embedded prompts on writing processes and products of novice and
advanced college writers.&QUOT; <i>Cognition and Instruction</i>, <b>8</b>
(1), 1-27.

<p> <a name="LOSEE1996">Losee, R.M. (1996)</a> &QUOT;Text windows and phrases differing by discipline, location in document, and syntactic structure&QUOT;, <i>Information Processing and Management</i>, <b>32</b> (6), 747-767.

<p> <a name="MARTI1987">Martinez, C., Lucey, J. and Linder, E. (1987)</a> &QUOT;An expert system for machine-aided indexing&QUOT;, <i>Journal of Chemical Information and Computer
Sciences</i>, <b>27</b> (4), 158-162.

<p> <a name="NISO1997">National Information Standards Organization (1997)</a> <i>Guidelines for
Abstracts</i> (ANSI Z39.14-1997)

<p> <a name="NIELS1994">Nielsen, J. (1994)</a> &QUOT;Estimating the number of subjects needed for a thinking aloud test.&QUOT; <i>International Journal of Human-Computer Studies</i>,
<b>41</b>, 385-397.

<p> <a name="PAICE1990">Paice, C. (1990)</a> &QUOT;Constructing literature abstracts by computer: techniques and prospects.&QUOT; <i>Information Processing and Management</i>, <b>26</b> (1), 171-186.

<p> <a name="PAIJM1993">Paijmans, H. (1993)</a> &QUOT;Comparing the document representations of two IR systems: CLARIT and TOPIC.&QUOT; <i>Journal of the American Society for Information
Science</i>, <b>44</b> (7), 383-392.

<p> <a name="R_TH1994">R &amp; TH Inc (1994)</a> <i>WinSpell Version 3.08: the Windows Spelling Supervisor</i>. Richardson, Texas: R &amp; TH Inc.

<p> <a name="SKY1998">SKY Software (1998)</a> &QUOT;Product Information.&QUOT; (<a
href="http://www.sky-software.com/prodinfo.htm" >http://www.sky-software.com/prodinfo.htm</a>, visited 1998 March 5)

<p> <a name="SRINI1996">Srinivasan, P., Ruiz, M.E. and Lam, W. (1996)</a> &QUOT;An
investigation of indexing on the WWW&QUOT, <i>in: ASIS '96: proceedings of
the 59th ASIS Annual Meeting (1996, volume 33), Baltimore, Maryland,
October 21-24, 1996</i>, edited by S. Hardin. Medford, New Jersey:
Information Today. pp.79-83.

<p> <a name="TIBBO1992">Tibbo, H.R. (1992)</a> &QUOT;Abstracting across the disciplines: a content analysis of abstracts from the natural sciences, the social sciences, and the humanities with implications for abstracting standards and online information
retrieval.&QUOT; <i>Library and Information Science Research</i>, <b>14</b>
(1), 31-56.

<h2>Appendix: an example of an abstract written using the package</h2>

<p>(The assistant's abstracts generally did not reach the stage of final editing. The following abstract, however, has been included in the documentation as an example of the sort of result that can be produced. The original is &quot;The Hidden Centre of the 'Gutenberg Galaxy'&quot; by Steve Mizrach [formerly available at http://www.clas.ufl.edu/anthro/cyberanthro/Gutenberg_Galaxy.html <strong><em>but no longer available in December 2002</em></strong>].)</p>

<blockquote> This is an attempt to refute the technological determinists'
assumption that technology is born by serendipity and does not cause social
changes until society decides to make some use of it. Two revolutionary
inventions - the printing press and electronic media - were planned by
people determined to achieve certain political and social goals. In the
book <i>The Lost Language of Symbolism</i> Harold Bayley analyzed the
heretical content of the watermarks or emblems used by paper makers and
then by printing guilds and concluded that probably the printers' guilds
knew that introducing widespread printing, just as with the introduction of
writing, would create losers and winners, but they might have known who the
losers would be beforehand, and possibly planned things this way. The early
pioneers in personal computing had the same agenda: they were fighting
against the elitist approach to computing. They believed PCs would put the
power of computing (by providing means for unlimited access and sharing of
information) in the 'little guy's' hands - just as the printing press meant
he could get his hands on what the priests and Schoolmen had already been
reading in the 15 century. </blockquote> 

<p> (The following phrases were extracted automatically from the source text, using the default threshold: &quot;of writing&quot;, &quot;people&quot;, &quot;the hidden center of the gutenberg galaxy&quot;, &quot;the printing press&quot;, &quot;word&quot;. The following frequent keywords were extracted: &quot;galaxy&quot;, &quot;gutenberg&quot;, &quot;people&quot;, &quot;printing&quot;,
&quot;word&quot;, &quot;writing&quot;.)</p>

<hr size="3" color="#FF00FF">
<p style="text-align : center; color : Red; font-weight : bold;">How to cite this paper:</i></p>
<p style="text-align : left; color : black;">Craven, Timothy C.   (1998)&nbsp; &quot;Human creation of abstracts with selected computer assistance tools.&quot;&nbsp;&nbsp;<em>Information Research</em>, <strong>3</strong>(4) Available at: http://informationr.net/ir/3-4/paper47.html</p>
<p style="text-align : center">&copy; the author, 1998. Updated 28th March 1998</p>
<hr color="#ff00ff" size="1">
								<div align="center">Articles citing this paper, <a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;safe=off&amp;q=link:KPD8ZdcckrUJ:scholar.google.com/" target="_blank">according to Google Scholar</a></div>
								 <hr color="#ff00ff" size="1">
<table border="0" cellpadding="15" cellspacing="0" align="center">
<tr> 
    <td><a href="infres34.html"><h4>Contents</h4></a></td>
   <td align="center" valign="top"><h5 align="center"><img src="http://counter.digits.com/wc/-d/-z/6/-b/FF0033/paper47" ALIGN=middle  WIDTH=60 HEIGHT=20 BORDER=0 HSPACE=4 VSPACE=2><br><a href="http://www.digits.com/">Web Counter</a><br>Counting only since 28 December 2002</h5></td>
    <td><a href="../index.html"><h4>Home</h4></a></td>
  </tr>
</table>
<hr color=#ff00ff size=3>




<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-672528-1";
urchinTracker();
</script>
</body>

<!-- Mirrored from informationr.net/ir/3-4/paper47.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:27 GMT -->
</html>

