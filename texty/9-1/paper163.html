<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<!-- Mirrored from informationr.net/ir/9-1/paper163.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:15:37 GMT -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<title>On conceptual models for information seeking and retrieval research</title>
<link href="../IRstyle.css" rel="stylesheet" />
<link rel="alternate stylesheet" type="text/css" media="screen" title="sans" href="../IRstylesans.css" />
<link rev="made" href="mailto:t.d.wilson@shef.ac.uk" />
<meta name="robots" content="all" />
<meta name="dc.title" content="On conceptual models for information seeking and retrieval research" />
<meta name="dc.creator" content="Kalervo Jarvelin, T.D. Wilson" />
<meta name="dc.subject" content="information behaviour, conceptual models" />
<meta name="dc.description" content="here are several kinds of conceptual models for information seeking and retrieval (IS&amp;R). The paper suggests that some models are of a summary type and others more analytic. Such models serve different research purposes. The purpose of this paper is to discuss the functions of conceptual models in scientific research, in IS&amp;R research in particular. What kind of models are there and in what ways may they help the investigators? What kinds of models are needed for various purposes? In particular, we are looking for models that provide guidance in setting research questions, and formulation of hypotheses. As a example, the paper discusses [at length] one analytical model of task-based information seeking and its contribution to the development of the research area." />
<meta name="dc.publisher" content="Professor T.D. Wilson" />
<meta name="dc.coverage.placename" content="global" />
<meta name="dc.subject.keywords" content="conceptual models, information seeking, information retrieval, models, hypotheses, task complexity, information behaviour" />
<meta name="dc.type" content="text" />
<meta name="dc.identifier" scheme="ISSN" content="1368-1613" />
<meta name="dc.relation.IsPartOf" content="infres91.html" />
<meta name="dc.format" content="text/html" />
<meta name="dc.language" content="en" />
<meta name="dc.rights" content="http://creativecommons.org/licenses/by-nd-nc/1.0/" />
<script language="javascript" type="text/javascript">

		var flag;
		flag = true;
		function doChangeFont()
		{
			if (flag)
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../sans.css');
			htmlDoc.appendChild(css);
			flag = false;
			} 
			else
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../IRstyle.css');
			htmlDoc.appendChild(css);
			flag = true;
			}	
		}
		
	</script>

<style type="text/css">
#button {
	width: 45em;
	padding: 0 0 0 0;
	font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	font-size: small;
	font-weight: bold;  
	background-color: #ffffff;
	color: #000000;
	display: inline;
	text-align: center;
	}
		

#button ul {
		list-style: none;
		margin: 0;
		padding: 0;
		border: none;
		display: inline;
		}
		
#button li {
		margin: 0;
		font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	    font-size: small;
	    font-weight: bold;  
		background-color: #fff000<!-- #2175bc; -->
		color: #000000;
		text-decoration: none;
		display: inline;
		}

#button li a:hover {
		background-color: azure;
		color: #ff0000;
		width: auto;
		}

</style>
<style type="text/css">
<!--
.style1 {color: #FF0000}
-->
</style>
</head>
<body  bgcolor="#ffffff">
<table align="center" border="0" cellpadding="0" cellspacing="0">
<tr><td height="30" align="center" colspan="5"> <img src="../mini_logo2.gif" width="336" height="45" alt="header" /><br />
Vol. 9  No. 1, October 2003<br /><br /><div id="button">
<ul>
	<li><a href="infres112.html">Contents</a> | </li>
	<li><a href="../iraindex.html">Author index</a> | </li>
	<li><a href="../irsindex.html">Subject index</a> | </li>
	<li><a href="../search.html">Search</a> | </li>
	<li><a href="../index-2.html">Home</a></li>
</ul>
</div></td></tr>
  <tr> 
    <td>&nbsp;</td>
  </tr>
</table>
<hr size="3" style="color:#000080 ;" />

<h1>On conceptual models for information seeking and retrieval research</h1>

<h4 align="center"><a href="mailto:kalervo.jarvelin@uta.fi">
Kalervo J&auml;rvelin
</a><br /> 
Centre for Advanced Study<br /> 
University of Tampere, Tampere, Finland<br /> 
and<br />
<a href="mailto:t.d.wilson@shef.ac.uk">
T.D. Wilson
</a><br />
Visiting Professor<br />
H&ouml;gskolan i Bor&aring;s, Bor&aring;s, Sweden</h4>
<br />
<div align="center">
<input type="button" value="change font" class="btn" style="font-variant: small-caps; font-weight: bold; font-family: Verdana; color: Blue;" onclick="doChangeFont()" /></div>
<hr size="1" style="color:#000080 ;" />
<div align="center"><b>Abstract</b></div>

<blockquote>There are several kinds of conceptual models for information seeking and retrieval (IS&amp;R). The paper suggests that some models are of a summary type and others more analytic. Such models serve different research purposes. The purpose of this paper is to discuss the functions of conceptual models in scientific research, in IS&amp;R research in particular. What kind of models are there and in what ways may they help the investigators? What kinds of models are needed for various purposes? In particular, we are looking for models that provide guidance in setting research questions, and formulation of hypotheses. As a example, the paper discusses [at length] one analytical model of task-based information seeking and its contribution to the development of the research area.</blockquote>  
<hr size="1" style="color:#000080 ;" />
<br />
 
<h2>Introduction</h2>

<p>There has been considerable interest in recent years in producing conceptual models for information seeking and retrieval (IS&amp;R) research. The recent paper by Wilson (<a href="#wil99">1999</a>) reviews models for information behaviour (<a href="#wil81">Wilson 1981</a>), information seeking behaviour (<a href="#wil81">Wilson 1981</a>; <a href="#wil96">1996</a>; <a href="#der86">Dervin, 1986</a>; <a href="#ell93">Ellis <em>et al</em>. 1993</a>, <a href="#kuh91">Kuhlthau, 1991</a>), and information searching or retrieval (<a href="#ing96">Ingwersen, 1996; Belkin, <em>et al</em>. 1995</a>; <a href="#spi97">Spink, 1997</a>).</p> 

<p>Wilson (<a href="#wil99">1999</a>: 250) notes concerning the models of information behaviour, among others, that &quot;<em>rarely do such models advance to the stage of specifying relationships among theoretical propositions: rather they are at a pre-theoretical stage, but may suggest relationships that might be fruitful to explore or test.</em>&quot;  Later he notes that,</p> 

<blockquote>&quot;[t]he limitation of this kind of model, however, is that it does little more than provide a map of the area and draw attention to gaps in research: it provides no suggestion of causative factors in information behaviour and, consequently, it does not directly suggest hypotheses to be tested.&quot; (<a href="#wil99">1999</a>: 251)</blockquote>

<p>It seems, therefore, that there may be several kinds of conceptual models for IS&amp;R and that, at least for some research purposes, we would need models that may suggest relationships that might be fruitful to explore and provide hypotheses to test.  The purpose of this paper is to discuss the functions of conceptual models in scientific research, in IS&amp;R research in particular. What kind of models are there and in what ways may they help the investigators? What kinds of models are needed for various purposes? In particular, we are looking for models that provide guidance in setting research questions, and formulating hypotheses. </p>

<p>In the following section we shall discuss the meaning and function of conceptual frameworks and principles for judging their merits in research. This extends Järvelin's (<a href="#jar87">1987</a>) discussion on criteria for assessing conceptual models for IS&amp;R research. Section 3 analyses briefly some summary frameworks for the IS&amp;R domain. This is followed by a  discussion of analytic frameworks. In particular, the classifications suggested by Järvelin are presented and their use in generating fruitful research hypotheses is discussed. Jarvelin's suggestions led to empirical study (<a href="#bys95">Bystr&ouml;m &amp; J&auml;rvelin, 1995</a>; <a href="#bys99">Bystr&ouml;m, 1999</a>) and theoretical development (<a href="#bys99">Bystr&ouml;m, 1999</a>; <a href="#vak87">Vakkari &amp; Kuokkanen, 1987</a>; <a href="#vak99">Vakkari, 1999</a>), which analysed the relationships of task complexity and information seeking. The uses for the classifications in later research are briefly summarised.  The paper ends with discussion and conclusions.</p> 

<h2>Conceptual models and their uses</h2>

<p>All research has an underlying model of the phenomena it investigates, be it tacitly assumed or explicit. Such models, called conceptual frameworks (<a href="#eng62">Engelbart, 1962</a>) or conceptual models, easily become topics of discussion and debate when a research area is in transition. Often two or more models are compared and debated. With an eye on advancing the research area, how should the models be assessed for their possible uses? In this section we discuss the function of conceptual frameworks and principles for judging their merits. </p>

<p>According to Engelbart, developing conceptual models means specifying the following:</p>

<ul>
<li>Essential objects or components of the system to be studied.</li>
<li>The relationships of the objects that are recognised.</li>
<li>What kinds of changes in the objects or their relationships affect the functioning of the system - and in what ways.</li>
<li>Promising or fruitful goals and methods of research.</li>
</ul>

<p>Conceptual models are broader and more fundamental than scientific theories in that they set the preconditions of theory formulation. In fact, they provide the conceptual and methodological tools for formulating hypotheses and theories. If they are also seen to represent schools of thought, chronological continuity, or principles, beliefs and values of the research community, they become paradigms. The conceptual model of a research area is always constructed - it does not simply lie somewhere waiting for someone to pick it up.</p> 

<p>The literature of the Philosophy of Science provides discussions on the functions of scientific theories. According to Bunge (<a href="#bun67">1967</a>), scientific theories are needed (or used) for the following functions:</p> 

<ul>
  <li>Systematisation of knowledge by: 
    <ul>
      <li>Integrating formerly separate parts of knowledge.</li>
      <li>Generalising and explaining lower abstraction level knowledge (or observations, 
        data) through higher level constructs.</li>
      <li>Explanation of facts through systems of hypotheses which entail the 
        facts.</li>
      <li>Expanding knowledge by deducing new propositions based on selected starting 
        points and collected information.</li>
      <li>Improving the testability of hypotheses through the control context 
        provided by systems of hypotheses.</li>
    </ul>
  </li>
  <li>Guiding research by:
     <ul>
      <li>Pointing to fruitful problems.</li>
      <li>Proposing the collection of data, which nobody would understand to collect 
        without the theory.</li>
      <li>Proposing totally new lines of research.</li>
    </ul>
  </li>
  <li>Mapping a portion of reality by:
    <ul>
      <li>Representing or modelling the objects (and relationships) of that chunk 
        instead of just summarising the data.</li>
      <li>Providing a tool for producing new data.</li>
    </ul>
  </li>
</ul>

<p>We believe that these functions are also suitable functions of conceptual models, which are more general in nature than theories. Clearly, conceptual models may and should map reality, guide research and systematise knowledge, for example, by integration and by proposing systems of hypotheses.</p> 

<p>A conceptual model provides a working strategy, a scheme containing general, major concepts and their interrelations. It orients research towards specific sets of research questions. A conceptual model cannot be assessed directly empirically, because it forms the basis of formulating empirically testable research questions and hypotheses.  It can only be assessed in terms of its instrumental and heuristic value. Typically, this happens by assessing the research strategies and programmes (and results) it creates. The latter programmes consist of interrelated substantial theories and research relevant for evaluating them (<a href="#wag92">
Wagner, <em><em>et al.</em></em>, 1992</a>; <a href="#vak98">Vakkari 1998</a>).  If the substantial theories prove to be fertile, the model is so too.</p>

<p>However, waiting for the substantial theories to prove to their fertility may take some time. In the meantime, or even before embarking on some line of research, it may be important to argue about the merits of various conceptual models. The following are the types of arguments that can be used to judge the merits of a conceptual model:</p>

<ul>
<li>General scientific principles:
<ul><li>When studying some phenomena, they should be studied in all situations, and also under extreme conditions (cf. thermophysics). Thus, you do not just consider information seeking by academics but also by other professions or by laymen.</li>
<li>The framework should be limited in a meaningful way as a system. For understanding information seeking by human actors, the proper system is not some service (for example, a library) and its clients but rather an information actor immersed in his or her situation and information environment (for example, all information access systems).</li>
</ul>
</li>
</ul>

<p>When two competing conceptual models are compared the following criteria may be applied to judge their merits:</p>

<ul>
<li>Simplicity: simpler is better other things being equal.</li>
<li>Accuracy: accuracy and explicitness in concepts is desirable.</li>
<li>Scope: a broader scope is better because it subsumes narrower ones, other things being equal.</li>
<li>Systematic power: the ability to organise concepts, relationships and data in meaningful systematic ways is desirable.</li>
<li>Explanatory power: the ability to explain and predict phenomena is desirable.</li>
<li>Reliability: the ability, within the range of the model, to provide valid representations across the full range of possible situations.</li>
<li>Validity: the ability to provide valid representations and findings is desirable.</li>
<li>Fruitfulness: the ability to suggest problems for solving and hypotheses for testing is desirable.</li>
</ul>

<p>Theoretical development or the construction of new conceptual models in any research area often requires conceptual and terminological development. Conceptual development may mean fulfilling, perhaps in a better way than before, the basic requirements for scientific concepts - precision, accuracy, simplicity, generality, and suitability for expressing propositions, which may be shown true or false. Moreover, good concepts represent essential features (objects, relationships, events) of the research area. More importantly, the concepts should differentiate and classify the phenomena in ways that lead to interesting hypotheses (or research problems). This means that the concepts must relate to each other in systematic and fruitful ways. Concepts also need to support research into the phenomena by known research methods (or, somewhat relaxed, by methods that can be developed). They need to be compatible with each other and with research methods (that is, be congruent).</p>

<h2>Summary frameworks</h2>

<h3>Two sample frameworks</h3>

<p>We will discuss Ellis's (<a href="#ell89">1989</a>; <a href="#ell93">Ellis, <em>et al.</em>, 1993</a>) and Ingwersen's (<a href="#ing96">1996</a>) frameworks. These are used and discussed here as examples only and we make no claims about their merits with respect to the research tasks for which they were originally intended.</p>

<p>Ellis's elaboration of the different behaviours involved in information seeking consists of six features. Ellis makes no claims to the effect that the different behaviours constitute a single set of stages; indeed, he uses the term 'features' rather than 'stages'.  These features are named and defined below:</p>

<ul>
<li>Starting: the means employed by the user to begin seeking information, for example, asking some knowledgeable colleague;</li>
<li>Chaining: following footnotes and citations in known material or 'forward' chaining from known items through citation indexes;</li>
<li>Browsing: 'semi-directed or semi-structured searching' (Ellis, 1989: 187);</li>
<li>Differentiating: using known differences in information sources as a way of filtering the amount of information obtained;</li>
<li>Monitoring: keeping up-to-date or current awareness searching;</li>
<li>Extracting: selectively identifying relevant material in an information source;</li>
<li>Verifying: checking the accuracy of information;</li>
<li>Ending: which may be defined as 'tying up loose ends' through a final search.</li>
</ul>

<p>The strength of Ellis's model is that it is based on empirical research and has been tested in subsequent studies, most recently in the context of an engineering company (<a href="#ell93">Ellis &amp; Haugan, 1997</a>).</p>
 
<p>Of the features, Ellis (<a href="#ell89">1989</a>: 178) notes that, '<em>...the detailed interrelation or interaction of the features in any individual information seeking pattern will depend on the unique circumstances of the information seeking activities of the person concerned at that particular point in time</em>'. Wilson (1999) proposes how these features may relate to each other temporally, providing a partial order; see Figure 1.</p>

<div align="center"><img src="p163fig1.gif" width="585" height="155" alt="figure1" /></div>
<br />
<div align="center">Figure 1. A process version of Ellis's behavioural framework (<a href="#wil99">Wilson 1999</a>)</div>


<p>One may <em>describe</em> any information seeking activities through Ellis's features. Indeed, they are general enough to fit a large number of empirical situations. However, if one is to <em>explain</em> information seeking behaviour, say, in terms of the work tasks the subjects are engaged with, or their knowledge on the task, the features fall short because they are not explicitly related to such external possible causative factors.</p> 

<p>Of course, Ellis's model may still be of indirect help in finding explanations for information seeking behaviour. It is possible to discern differences in any of the 'features' in different situations, involving different kinds of persons through successive research projects. For example, some persons in some roles may be shown to engage more or less in monitoring than other persons. This may then lead to an examination of the factors that 'cause' these differences.</p> 

<div align="center"><img src="p163fig7.jpg" width="477" height="432" alt="ingwersenmodel" /></div>

<div align="center">Figure 2. Ingwersen's model of the IR process (Wilson, 1999; based on <a href="#ing96">Ingwersen, 1996</a>)</div>

<p>Ingwersen's (<a href="#ing96">1996</a>) model is slightly simplified in Figure 2. Wilson points out its relationships to other models of information seeking behaviour. In particular, the elements <em>user's cognitive space</em> and <em>social/organisational environment</em>, resemble the <em>person in context</em> and <em>environmental factors</em> specified in Wilson's models (<a href="#wil81">1981</a>, <a href="#wil96">1996</a>; <a href="#wil99">1999</a>). The general orientation towards queries posed to an IR system point to a concern with the <em>active search</em>, which is the concern of most information-seeking models. Ingwersen, however, makes explicit a number of other elements: first, he demonstrates that within each area of his model, the functions of the information user, the document author, the intermediary, the interface and the IR system are the result of explicit or implicit cognitive models of the domain of interest at that particular point.  Thus, users have models of their work-task or their information need, or their problem or goal, which are usually implicit, but often capable of explication.  Again, the IR system is an explication of the system designer's cognitive model of what the system should do and how it should function.  Secondly, Ingwersen brings the IR system into the picture, suggesting that a comprehensive model of information-seeking behaviour must include the system that points to the information objects that may be of interest to the enquirer.  Thirdly, he shows that various cognitive transformations take place in moving from the life-world in which the user experiences a problem or identifies a goal to a situation in which a store of pointers to information objects can be satisfactorily searched and useful objects identified.  Finally he points to the need for these cognitive structures and their transformations to be effectively communicated throughout the 'system', which will include the user, the author and the IR system designer. All this true&mdash;it is easy to agree.</p>

<p>Thus, Ingwersen's model, to a degree, integrates ideas relating to information behaviour and information needs with issues of IR system design, and this is an important strength of the model. Saracevic suggests that (<a href="#sar96">1996</a>): <em>'The weakness is in that it does not provide for testability... and even less for application to evaluation of IR systems.' </em> However, recently, Borlund and Ingwersen (<a href="#bor97">
1997</a>; <a href="#bor98">1998</a>; <a href="#bor00">Borlund, 2000</a>) have developed and tested an evaluative strategy on the basis of this model and have demonstrated its value in testing interactive IR systems.  A remaining potential weakness is that information behaviour other than information retrieval is not explicitly analysed. Issues of how users arrive at the point of making a search, and how their cognitive structures are affected by the processes of deciding how and when to move towards information searching, may be lost. These issues may be discussed in terms of the social or organisational environment but, to say the least, this is not explicit.</p>

<p>In Ingwersen's model, there are several entities of the IS&amp;R interplay present, and some of their relevant features are explicated. Therefore, there are better possibilities for formulating research questions for empirical study; for example, how is an individual user's uncertainty related to the intermediary functions, and how does this affect the retrieval process? However, there is still some way to go before one may say that an empirical research problem has been specified.  This could be done by classifying, for example, uncertainty and intermediary functions in ways that suggest empirical relationships.</p>

<h3>Uses of summary frameworks</h3>

<p>Summary models provide overviews of research domains, and list factors affecting the phenomena.  It is often easy to agree that, what the models propose, are factors affecting the processes of interest. However, without detailed analysis of the components, such models provide little or no suggestion of causative factors in IS&amp;R phenomena and, consequently, they do not directly suggest hypotheses to be tested. Indirectly, however, a comparison of findings across several studies may suggest causative factors to be explored.</p>

<h2>An analytic framework</h2>

<p>J&auml;rvelin (<a href="#jar87">1987</a>) suggested three classifications and discussed their use in generating fruitful research hypotheses for the analysis of the relationships of task complexity and information seeking. Bystr&ouml;m and J&auml;rvelin (<a href="#bys95">1995</a>; <a href="#bys99">Bystr&ouml;m 1999</a>) revised the classification and carried out an empirical study, and Bystr&ouml;m (<a href="#bys99">1999</a>) and Vakkari (<a href="#vak98">1998</a>; <a href="#vak99">1999</a>) suggested theoretical developments. We first present the classifications and then discuss their theoretical and methodological consequences.</p>

<h3>Task complexity</h3>

<p>A worker's job consists of tasks, which consist of levels of progressively smaller subtasks. Tasks are either given to, or identified by, the worker. Each task has a recognisable beginning and end, the former containing recognisable stimuli and guidelines concerning goals and/or measures to be taken (<a href="#hac69">Hackman, 1969</a>). Seen in this way, both a large task or any of its (obviously simpler) sub-tasks may be considered as a task. This relativity in definition is necessary in order to analyse tasks of different levels of complexity.</p> 

<p>In information seeking we are interested in information-related tasks. These can be seen as perceived (or subjective) tasks or objective tasks. The relationships of objective and perceived tasks have been considered in organisational psychology (<a href="#cam88">Campbell, 1988</a>; <a href="#hac69">Hackman, 1969</a>; <a href="#woo86">Wood, 1986</a>) where task descriptions based on perceived tasks are generally held invalid for many purposes (for example, <a href="#rob81">Roberts &amp; Glick, 1981</a>). However, in information seeking, perceived tasks must be considered because each worker may interpret the same objective task differently (for example, as regards its complexity) and the perceived task always forms the basis for the actual performance of the task and for interpreting information needs and the choice of promising actions for satisfying them. </p>

<p>The literature suggests many task characteristics related to complexity: repetition, analysability, <em>a priori</em> determinability, the number of alternative paths of task performance, outcome novelty, number of goals and conflicting dependencies among them, uncertainties between performance and goals, number of inputs, cognitive and skill requirements, as well as the time-varying conditions of task performance (<a href="#cam88">Campbell, 1988</a>; <a href="#daf88">Daft <em>et al.</em>, 1988</a>; <a href="#fis79">Fischer, 1979</a>; <a href="#fis61">Fiske &amp; Maddi, 1961</a>;  <a href="#har91">Hart &amp; Rice, 1991</a>; <a href="#jar86">J&auml;rvelin, 1986</a>; <a href="#mar67">March &amp; Simon, 1967</a>; <a href="#mac84">MacMullin &amp; Taylor, 1984</a>; <a href="#tia92">Tiamiyu, 1992</a>; <a href="#tus78">Tushman, 1978</a>; <a href="#van80">Van de Ven &amp; Ferry, 1980</a>; <a href="#woo86">Wood, 1986</a>; <a href="#zef93">Zeffane &amp; Gul, 1993</a>). Also, these characteristics have been understood in many different ways in the literature. They belong in two main groups: characteristics related to the <em>a priori</em> determinability of tasks, and characteristics related to the extent of tasks.</p>

<p>J&auml;rvelin (<a href="#jar87">1987</a>; <a href="#bys95">Bystr&ouml;m and J&auml;rvelin, 1995</a>) suggest a simple, one-dimensional categorisation of the complexity of tasks based on, from the worker's point of view, <em>a priori</em> determinability of, or uncertainty about, task outcomes, process and information requirements. This dimension is related to the above task characteristics: repetition, analysability, <em>a priori</em> determinability, the number of alternative paths of task performance and outcome novelty. Similar one-dimensional categorisations of complexity are used by Tiamiyu (<a href="#tia92">1992</a>) and Van de Ven and Ferry (<a href="#van80">1980</a>). Simple tasks are routine information processing tasks, where the inputs, process and outcomes can be determined <em>a priori</em>, while difficult or complex tasks are new and genuine decision tasks, which cannot be so determined. Such a categorisation is generic and, thus, widely applicable to many types of tasks and domains.</p> 

<h3>Task categorisation</h3>

<p>In this paper, tasks are classified into five categories ranging from an automatic information-processing task to a genuine decision task. This categorisation is based on the <em>a priori</em> determinability (or structuredness) of tasks and is closely related to task difficulty or complexity. </p>

<p>Task complexity is often seen to depend on the degree of <em>a priori</em> uncertainty about the task inputs, process and outcome (for example, <a href="#van80">Van de Ven &amp; Ferry, 1980</a>). In automatic information processing tasks, the type of the task result, the work process through the task, and the types of information used can all be described in detail in advance. In genuine decision tasks, on the contrary, none can be determined <em>a priori</em>.<sup><a href="#note1">
1
</a></sup> Our task categorisation is presented in Fig. 3 where information (both input and result) is represented by arrows and the task process by boxes. The <em>a priori</em> determinable parts of tasks are represented by solid arrows and solid boxes, and the <em>a priori</em> indeterminable parts of tasks are represented by dashed arrows and shaded boxes. Dashed arrows and shaded boxes thus represent cased-based arbitration. Three arrows are used in the input side to visualise that many inputs often are needed and that there are degrees of <em>a priori</em> determinability among them. Also the types of input differ by task category as discussed in the next subsection. </p>

<div align="center"><img src="p163fig3.gif" width="458" height="614" alt="figure3" /></div>
<br />
<div align="center">
Figure 3: Task categories (Anon. 1974)
</div>

<p>Tasks in different categories can be characterised briefly as follows:</p>

<ul>
<li><em>Automatic information processing tasks</em> are <em>a priori</em> completely determinable so that, in principle, they could be automated - whether actually automated or not. Example: computation of a person's net salary yields a real number in some known range and requires this person's gross salary and tax code, and the taxation table.</li>
<li><em>Normal information processing tasks</em> are almost completely <em>a priori</em> determinable but require some case-based arbitration concerning for example, the sufficiency of the information normally collected. Thus part of the process and information needed is <em>a priori</em> indeterminable. Example: tax coding is mostly rule-based but some cases require additional clarification, that is, case-dependent information collection.</li>
<li><em>Normal decision tasks</em> are still quite structured but in them cased-based arbitration has a major role. Example: hiring an employee or evaluating a student's term paper.</li>
<li>In <em>known, genuine decision tasks</em> the type and structure of the result is <em>a priori</em> known but permanent procedures for performing the tasks have not yet emerged. Thus, the process is largely indeterminable and so are its information requirements. Example: deciding about the location for a new factory or medium-range planning in organisations.</li>
<li><em>Genuine decision tasks</em> are unexpected, new and unstructured. Thus, neither the result, the process nor the information requirements can be characterised in advance. The first concern is task structuring. Example: the collapse of the Soviet Union from the viewpoint of other governments.</li>
</ul>

<p>Information seeking research has focused mostly on tasks in the middle and upper parts of the categories (normal decision task to genuine decision task) although this dimension has only rarely been recognised. Belkin (<a href="#bel80">1980</a>) describes a similar scale of problem situation levels). The categories above are relative to the worker: what is a genuine decision task to a novice may be a normal decision to an expert.</p> 

<h3>Types of information needed in tasks</h3>

<p>In expert systems design, the types of information are classified as problem information (PI), domain information (DI), and problem solving information (PSI) (for example, <a href="#bar81">Barr &amp; Feigenbaum, 1981</a>). J&auml;rvelin and Repo (<a href="#jar83">1983</a>; <a href="#jar84">1984</a>) proposed these concepts for information seeking research. These information categories can be characterised as follows: </p>

<ul>
<li><em>Problem information</em> describes the structure, properties and requirements of the problem at hand. For example, in bridge construction, information on the type and purpose of the bridge and on the building site constitute problem information. It is typically available in the problem environment, but, in the case of previous problems of the same type, it may also be available in documents.</li>

<li><em>Domain information</em> consists of known facts, concepts, laws and theories in the domain of the problem. For example, in bridge construction, information on the strength and thermal expansion of steel belongs to domain information. This is, typically, tested scientific and technological information published in journals and textbooks. </li>

<li><em>Problem-solving information</em> covers the methods of problem treatment. It describes how problems should be seen and formulated, what problem and domain information should be used (and how) in order to solve the problems. For example, in bridge construction, the design engineer's heuristics concerning the pros and cons of various bridge design types constitute problem-solving information. It is instrumental information and typically available only from knowledgeable persons (or experts). </li> 
</ul>

<p>These three information categories are orthogonal, that is, represent three different dimensions and have different roles in problem treatment. All are necessary in problem treatment but, depending on the task, and to different degrees, may be available to a worker performing the task. Because their typical sources are different, typical channels for acquiring them may also be different.</p>

<p>Regarding Figure 3, the solid arrows representing input information may be seen as <em>a priori</em>  determinable problem information whereas the dashed arrows would represent all <em>a priori</em>  indeterminable information, often problem-solving information. </p>

<h3>Types of Information Sources</h3>

<p>Bystr&ouml;m and J&auml;rvelin (<a href="#bys95">1995</a>) classified the types of information sources as:</p>

<ul>
<li><em>fact-oriented</em>:
<ul>
<li>registers (manual and computerised catalogues and files)</li>
<li>commercial databases</li>
</ul>
</li>
<li><em>problem-oriented</em>:
<ul>
<li>the people concerned (for example, people proposing, or affected by, administrative actions)</li>
<li>official documents (for example, agendas, meeting minutes, letters, applications, memoranda, maps, unpublished planning documents)</li>
</ul>
</li>
<li><em>general-purpose</em>:
<ul>
<li>experts (including knowledgeable colleagues)</li>
<li>literature (for example, books, reports, journals, newspapers)</li>
<li>personal collections (personal notes, calculations, etc.)</li>
</ul>
</li>
</ul>

<p>They also classified the sources as being either <em>internal</em> or <em>external</em> to the organisation in which the user works.</p>

<h3>Theoretical and methodological consequences</h3>

<p>Bystr&ouml;m and J&auml;rvelin used their framework, the three classifications of tasks, information and information sources, for the analysis of their data structured in work charts (Figure 4). In combination, the three classifications suggest a set of hypotheses of the type: &quot;<em>Tasks of complexity type X require information of type Y that is available from sources of type Z</em>&quot;. Thus the classifications suggest analytical relationships between the variables.</p>

<div align="center"><img src="p163fig4.gif" width="615" height="493" alt="figure4" /></div>
<br />
<div align="center">Figure 4: The work chart structure (<a href="#bys95">Bystr&ouml;m and J&auml;rvelin, 1995
</a>)</div>

<p>Bystr&ouml;m and J&auml;rvelin (<a href="#bys95">1995</a>; <a href="#mur92">Murtonen, 1992</a><sup><a href="#note2">2</a></sup>) developed a qualitative method for task-level analysis of the effects of task complexity on information seeking and found, in a public administration context, that these effects are systematic and logical. The specific research problem studied was: what types of information are sought through which types of channels from what kinds of sources in which kinds of tasks? They found that, as task complexity increased, so:</p>

<ul>
<li>the complexity of information needed increased,</li>
<li>the needs for domain information and problem solving information increased,</li> 
<li>the share of general-purpose sources (experts, literature, personal collections) increased and that of problem and fact-oriented sources decreased,</li>
<li>the success of information seeking decreased, </li>
<li>the internality of channels decreased, and </li>
<li>the number of sources increased.</li>
</ul>

<p>The contrast between simple and complex tasks underlines the importance and consequences of task complexity: in the latter understanding, sense-making and problem formulation are essential and require different types and more complex information through somewhat different types of channels from different types of sources.</p> 

<p>Bystr&ouml;m followed on with further empirical studies (<a href="#bys99">1999</a>; <a href="#mur94">Murtonen, 1994</a>). Based on her empirical findings, Bystr&ouml;m presented a revised model of task-based information seeking (Figure 5). The model contains eleven statements (S1 - S11 in Figure 5). Some of the statements are given below (all are given in the <a href="#app">Appendix</a>):</p>

<ul>
<li>S2: the more information types are needed, the greater the share of people as sources.</li>
<li>S6: the higher the degree of task complexity, the more probable is the need for multiple information types: first task information, then task and domain information, and finally task, domain and [problem] solving information.</li>
<li>S8: the higher the degree of task complexity, the more information types are needed and the greater the share of general-purpose sources and the smaller the share of task-oriented sources.</li>
<li>S10: task complexity is distinctly related to increasing internality of people as sources and decreasing internality of documentary sources.</li>
<li>S11: Increasing task complexity fosters the use of people as sources.</li>
</ul>

<div align="center"><img src="p163fig5.gif" id="figure5" name="figure5" width="552" height="581" alt="figure 5" /></div>
<br />
<div align="center">Figure 5: A model of task-based information seeking (<a href="#bys99">Bystr&ouml;m, 1999</a>)</div>

<p>Vakkari (<a href="#vak98">1998</a>; <a href="#vak99">1999</a>; <a href="#vak97">Vakkari &amp; Kuokkanen,  1997</a>) analysed, and contributed to, theory growth in task-based information seeking. Vakkari and Kuokkanen  apply Wagner &amp; Berger's (<a href="#vak98">1985</a>) analysis of theory growth to reconstructing a theory based on the framework by Bystr&ouml;m and J&auml;rvelin (<a href="#bys95">1995</a>). Vakkari and Kuokkanen note that the latter did not fully utilise the whole potential of the framework, for example, the relationships of information types and source use was not fully developed. They derive new hypotheses for further empirical work from the reconstructed theory. The resulting theory is thus broader in scope and has more empirical consequences than the original. Vakkari and Kuokkanen state that their reconstruction creates potential growth of knowledge within the theory of information seeking. This is easy to agree.</p>

<p>Vakkari (<a href="#vak98">1998</a>) further uses Wagner &amp; Berger (<a href="#wag85">1985</a>) and focuses on the theoretical research programme starting from Tushman's (<a href="#tus78">1978</a>) study on task complexity and information. He finds that Bystr&ouml;m and J&auml;rvelin's (<a href="#bys95">1995</a>) work created progress in all dimensions of theory growth, especially in terms of precision and scope. The framework (research programme), by adding the classification of information types, explicated several new factual relations among information seeking phenomena. </p>

<p>The empirical findings and theoretical developments by Bystr&ouml;m, J&auml;rvelin and Vakkari classify tasks, information and information sources in a systematic way. The latter are also systematically related to other central concepts of information seeking in a systematic way. The original papers suggested some classifications of essential phenomena. The original classifications were really simple, even trivial, when presented. However, they suggested specific systematic relationships to be explored. This led, in later papers, to thorough empirical work and theoretical development. This is an example of how proper analytic models may aid research in a specific area, such as information seeking.</p>

<h2>Discussion and conclusions</h2>

<p>The previous section presented a framework for information seeking studies that directly suggested research questions and hypotheses for testing. Such frameworks are clearly needed in building up a knowledge base in the IS&amp;R domain. Unfortunately, the work discussed above is not complete and we cannot present a well thought-out complete framework. There is room for further work, which is not the purpose of the present paper. Moreover, the model discussed is very specific, it does not attempt to cover all phenomena related to [task-based] information seeking. </p> 

<p>However, as a small contribution to further development, we can point to the fact that the model makes no reference to the characteristics of the person (apart from the possibility that novices and experts will behave differently), or to the field in which the person works. Other investigations have drawn attention to individual personality as a determinant of information-seeking behaviour (e.g., <a href="#ker73">Kernan &amp; Mojena, 1973
</a>; <a href="#bell85">Bellardo, 1985</a>; <a href="#pal91">Palmer, 1991</a>), and to the discipline or context within which the person works (e.g., <a href="#ano65">Anon., 1965</a>; <a href="#aus94">Auster &amp; Choo, 1994</a>; <a href="#fab98">Fabritius, 1998</a>; <a href="#gre96">Greene &amp; Loughridge, 1996</a>; <a href="#her67">Herner &amp; Herner, 1967</a>; <a href="#sia98">Siatri, 1998</a>; <a href="#tim89">Timko &amp; Loynes, 1989</a>; <a href="#wil80">Wilson &amp; Streatfield, 1980</a>). For example, the fact that more complex decisions involve more searching for people as sources of information may differ depending upon the person's 'need for affiliation' (<a href="#mcc61">McClelland, 1961</a>). </p>

<p>From the point of view of context or discipline, even in the field of public administration, for example, there may be significant differences in the nature of the tasks in, say, a planning department and a more 'people oriented' department such as social work. In the former, the processing of applications may involve much more decision making of a formal, technical nature, while in the latter, the concern with people's personal and domestic problems may result in decisions that have consequences that are more difficult to assess. We can suggest, therefore, a distinction between decisions that are related to a 'concern for process' and those that are related to a 'concern for person'. </p>

<p>We can also note that the distinction between 'information' and 'advice' is not sufficiently explored, although we suspect that the increased use of people as sources in complex decisions may have as much to do with the ability of people to guide, evaluate and advise, as with their possession of expert knowledge. Previous work on the affective dimension of information behaviour may also be relevant here (<a href="#wil81">Wilson, 1981</a>; <a href="#kuh93">Kuhlthau, 1993</a>). </p>

<p>Finally, we can also point to a second dimension of decisions: as noted above, the present framework uses one dimension &quot;<em>a priori</em> determinability of, or uncertainty about, task outcomes, process and information requirements&quot;. Thompson (<a href="#tho67">1967</a>) proposed two dimensions, one of which is similar to that used here, &quot;Preference regarding possible outcomes&quot;, which might be 'certainty' or 'uncertainty'. The second dimension is &quot;Beliefs about cause/effect relationships&quot;, which, again, might be 'certain' or 'uncertain'. The matrix that results from the combination of these two dimensions gives four types of decision processes, as shown in Figure 6. </p>

<div align="center"><img src="p163fig6.gif" width="597" height="132" alt="figure6" /></div>
<br />
<div align="center">Figure 6: Decision processes (based on Thompson, 1967)</div>

<p>The conceptual richness that results from the addition of a second dimension would give rise to an additional set of hypotheses relating the use of information sources to decision process. For example, one might hypothesise that decisions requiring 'judgement' will involve more information seeking activity and a greater use of discussions with colleagues, than other types of decision process, while 'inspiration' may require more personal 'thinking time' and use of a greater variety of information sources.</p>

<p>We return to the requirements on conceptual frameworks presented above. The framework developed by Bystr&ouml;m, J&auml;rvelin and Vakkari, through several studies, may be claimed to meet several of the requirements. In Engelbart's terms, it suggests that tasks, information, and information channels and sources are central objects in information seeking. It further suggests how these objects are related to each other. The hypotheses generated were (are) fruitful goals for further research. </p> 

<p>Regarding Bunge's (<a href="#bun67">1967</a>) functions for scientific theories, here applied for assessing conceptual frameworks, we find the following when assessing the Bystr&ouml;m, J&auml;rvelin and Vakkari framework: </p>
<ul>
<li>Systematisation of knowledge by:

<ul>
<li>Integrating formerly separate parts of knowledge: <em>Task complexity studies from organisational research are integrated with information seeking studies. .</em></li>
<li>Generalising and explaining lower abstraction level knowledge (or observations, data) through higher level constructs: <em>Specific information needed and sought, much studied in information seeking, is analysed in terms of types of information. .</em></li>
<li>Explanation of facts through systems of hypotheses, which entail the facts: <em>The framework suggested and allowed verification of several hypotheses of the research domain, cf. Bystr&ouml;m's S1-S11. .</em></li>
<li>Expanding knowledge by deducing new propositions based on selected starting points and collected information: <em>The later empirical and theoretical developments clearly expanded the original approach - Vakkari and Kuokkanen added to the original findings and unit theory. .</em></li>
<li>Improving the testability of hypotheses through the control context provided by systems of hypotheses: <em>The classifications generated many related hypotheses (e.g., Bystr&ouml;m's S1 - S11) which provided, for each hypothesis, a context for its verification. .</em></li>
</ul></li>

<li>Guiding research by:

<ul>
<li>Pointing out fruitful problems: <em>From the beginning, the framework saw tasks, as opposed to whole jobs, related to information seeking through the types of information needed in tasks. The latter were seen to vary along task complexity. .</em></li>
<li>Proposing the collection of data, which nobody would think to collect without the theory: <em>The framework suggested data to be collected on task complexity, task-related information seeking and the types of information needed. These were novel ideas in the late 1980s in information seeking research.</em></li>
<li>Proposing totally new lines of research: <em>The framework was one approach, among others, towards the task-centred line of information seeking research.</em></li>
</ul>
</li>
<li>Mapping an area of reality by:

<ul>
<li>Representing or modelling the objects (and relationships) of that area instead of just summarising the data: <em>While early research in information seeking summarised job-level information seeking, sources and preferences, the framework suggested tasks and information types as explaining the phenomena.</em>.</li>
<li>Providing a tool for producing new data: <em>The framework was a useful tool for generating hypotheses, and the associated research methods allowed the production of the required data.</em></li>
</ul>
</li>
</ul>

<p>Regarding general scientific principles, suggested above, for the assessment of conceptual frameworks, we may point out the following:</p>

<ul>
<li>The framework is general in the sense that it supports the analysis of task-based information seeking for any kinds of tasks through categories that are not limited to special contexts, for example, academics. The tasks need not be job-related, leisure tasks do as well.</li>
<li>The framework suggests perceived tasks, needed information and information seeking as a meaningful system. From the person or actor viewpoint this is much more meaningful than the information source and system framework (of many earlier studies) alone.</li>
</ul>

<p> Further desiderata for conceptual models were:</p>

<ul>
<li>
Simplicity: simpler is better other things being equal. <em>The framework is based on very simple classifications.</em>
</li>
<li>
Accuracy: accuracy and explicitness in concepts is desirable. <em>The framework could be more accurate and explicit in its classification on task complexity. Nevertheless, it has functioned well as a first approximation. The framework is more accurate than its predecessors in its focus on task-level instead of job-level. </em>
</li>
<li>
Scope: a broader scope is better because it subsumes narrower ones, other things being equal. <em>The framework is broader in its hospitability to any kind of tasks, not just job-related. On the other hand, it covers just three concepts, albeit important ones, of information seeking - a broader framework would incorporate other concepts as discussed above. </em>
</li>
<li>
Systematic power: the ability to organise concepts, relationships and data in meaningful systematic ways is desirable. <em>This clearly is one strong feature of the framework. </em>
</li>
<li>
Explanatory power: the ability to explain phenomena reliably and to predict them is desirable. <em>This clearly is one strong feature of the framework; it suggested several hypotheses that were later confirmed. </em>
</li>
<li>
Validity: the ability to provide valid representations and findings is desirable. <em> (No model can directly argue for being valid) </em>
</li>
<li>
Fruitfulness: the ability to suggest problems for solving and hypotheses for testing is desirable. <em> The number of studies that followed suggests at least some fruitfulness. </em>
</li>
</ul>

<p>We do not wish to make any claims about the usefulness or significance of this framework in comparison to other approaches within information seeking research. Rather, we wish to point out its formal merits: because of its characteristics, it has been successful in generating research that seems to have led to empirical and theoretical developments in the area of information seeking. Such models are needed in information science. According to Vakkari and Kuokkanen (<a href="#vak97">1997</a>), in order to create new knowledge in information science, we need clear, conceptually structured descriptions of the research objects. Without them the utilisation of research results in further studies is hampered. That would lead to slow or non-existent growth of knowledge in the field while findings may still amass.</p>

<hr size="3" style="color:#000080 ;" />
<h2 style="font-size: small; text-align: center; text-indent: 8%;">Send your comments on this paper to the journal's discussion list - join <a href="http://www.jiscmail.ac.uk/lists/IR-DISCUSS.html" target="_blank">IR-discuss</a></h2>
<hr size="3" style="color:#000080 ;" />

<h2>Notes</h2>

<p><a id="note1" name="note1" />1. It is this factor of determinability that helps us to define the 'automatic information processing' task. In such a task the outcome is determinable in advance. While a computer may be programmed to undertake tasks, which are computationally simple, such as those in a chess game, the outcome of the computer's calculations will not be determinable in advance, because of the complexity of the game.</p>
<p><a id="note2" name="note2" />2. Murtonen is the maiden name of Bystr&ouml;m.</p>

<h2>References</h2>

<ul>
<li><a id="ano65" name="ano65" />Anon. (1965). Survey of information needs of physicists and chemists. <em>Journal of Documentation</em>, <strong>21</strong>(2), 83-112.</li>
<li><a id="ano74" name="ano74" />Anon. (1974). <em>Tietosysteemin rakentaminen</em> [Information system design]. Helsinki: Tietojenk&auml;sittelyliitto. (Publication no. 25). (In Finnish).</li>
<li><a id="aus94" name="aus94" />Auster, E., &amp; Choo, C. W. (1994). How senior managers acquire and use information in environmental scanning. <em>Information Processing and Management</em>, <strong>30</strong>(5), 607-618.</li>
<li><a id="bar81" name="bar81" />Barr, A. &amp; Feigenbaum, E., (Eds.), (1981). <em>Handbook of artificial intelligence: Volume I.</em> London: Pitman.</li>
<li><a id="bel80" name="bel80" />Belkin, N.J. (1980). Anomalous state of knowledge for information retrieval. <em>Canadian Journal of Information Science</em>, <strong>5</strong>, 133-143.</li>
<li><a id="bel95" name="bel95" />Belkin, N.J. Cool, C., Stein, A., &amp; Thiel, U.  (1995). Cases, scripts and information seeking strategies: on the design of interactive information retrieval systems. <em>Expert Systems with Application</em>, <strong>9</strong>(3), 379-395.</li>
<li><a id="bell85" name="bell85" />Bellardo, T. (1985). An investigation of online searcher traits and their relationship to search outcome. <em>Journal of the American Society for Information Science</em>, <strong>36</strong>(4), 241-250</li>

<li><a id="bor00" name="bor00" />Borlund, P. (2000). Experimental components for the evaluation of interactive information retrieval systems. <em>Journal of Documentation</em>, <strong>56</strong>(1), 71-90.</li> 

<li><a id="bor97" name="bor97" />Borlund, P. &amp; Ingwersen, P. (1997). The development of a method for the evaluation of interactive information retrieval systems. <em>Journal of Documentation</em>, <strong>53</strong>(3), 225-250.</li> 

<li><a id="bor97" name="bor97" />Borlund, P. &amp; Ingwersen, P. (1998). Measures of relative relevance and 
ranked half-life: performance indicators for interactive IR. In: W.B. Croft, A. Moffat, C.J. van Rijsbergen, R. Wilkinson &amp; J. Zobel (eds.), <em>Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. New York, NY: Association for Computing Machinery: 324331.</li>  


<li><a id="bun67" name="bun67" />Bunge, M.A. (1967).  <em>Scientific research.</em> (2 vols.) Heidelberg: Springer-Verlag.</li>
<li><a id="bys99" name="bys99" />Bystr&ouml;m, K. (1999). <em>Task complexity, information types and information sources.</em> Doctoral Dissertation. Tampere: University of Tampere. (Acta Universitatis Tamperensis 688).</li>
<li><a id="bys95" name="bys95" />Bystr&ouml;m, K. &amp; J&auml;rvelin, K. (1995). Task complexity affects information seeking and use. <em>Information Processing &amp; Management</em>, <strong>31</strong>(2), 191 - 213.</li>
<li><a id="cam88" name="cam88" />Campbell, D.J. (1988). Task complexity: a review and analysis. <em>Academy of Management Review</em>, <strong>13</strong>(1), 40-52.</li>
<li><a id="daf88" name="daf88" />Daft, R.L. &amp; Sormunen, J. &amp; Parks, D. (1988). Chief executive scanning, environmental characteristics, and company performance: an empirical study. <em>Strategic Management Journal</em>, <strong>9</strong>(2), 123-139.</li>
<li><a id="der86" name="der86" />Dervin, B. &amp; Nilan, M. (1986). Information needs and uses. <em>Annual review of information science and technology</em>, <strong>21</strong>, 3-33.</li>
<li><a id="ell89" name="ell89" />Ellis, D. (1989). A behavioural approach to information retrieval design. <em>Journal of Documentation</em>, <strong>46</strong>(3), 318-338.</li>
<li><a id="ell93" name="ell93" />Ellis, D. &amp; Cox, D. &amp; Hall, K. (1993). A comparison of the information seeking patterns of researchers in the physical and social sciences. <em>Journal of Documentation</em>, <strong>49</strong>(4), 356-369.</li>
<li><a id="eng62" name="eng62" />Engelbart, D.C. (1962). <em><a href="http://www.bootstrap.org/augdocs/friedewald030402/augmentinghumanintellect/ahi62index.html" target="_blank">Augmenting human intellect: a conceptual framework.</a></em> Menlo Park, CA: Stanford Research Institute. (Summary report AFOSR-3233) Retrieved 27 September 2003 from http://www.bootstrap.org/augdocs/friedewald030402/augmentinghumanintellect/ahi62index.html </li> 

<li><a id="fab98" name="fab98" />Fabritius, H. (1998). <a href="../4-2/isic/fabritiu.html">
Information seeking in the newsroom. Application of the cognitive framework for analysis of the work context.
</a> <em>Information Research</em>, <strong>4</strong>(2). Retrieved 27 September, 2003, from http://informationr.net/ir/4-2/isic/fabritiu.html</li>

<li><a id="fis79" name="fis79" />Fischer, W.A. (1979). The acquisition of technical information by R&amp;D managers for problem solving in nonroutine contingency situations. <em>IEEE Transactions on Engineering Management</em>, <strong>26</strong>(1), 8-14.</li>

<li><a id="fis61" name="fis61" />Fiske, D.W. &amp; Maddi, S.R. (1961). Functions of varied-experience. Homewood, IL: Dorsey Press.</li>

<li><a id="gre96" name="gre96" />Greene, F. &amp; Loughbridge, B. (1996). <a href="../1-3/paper8.html">
Investigating the management information needs of academic Heads of Department: a Critical Success Factors approach. </a> <em>Information Research</em>, <strong>1</strong>(3) Retrieved 27 September, 2003, from http://informationr.net/ir/1-3/paper8.html</li>

<li><a id="hac69" name="hac69" />Hackman, J.R. (1969). Toward understanding the role of tasks in behavioral research. <em>Acta Psychologica</em>, <strong>31</strong>, 97-128.</li>

<li><a id="har91" name="har91" />Hart, P.J. &amp; Rice, R.E. (1991). Using information from external databases: contextual relationships of use, access method, task, database type, organizational differences, and outcomes. <em>Information Processing &amp; Management</em>, <strong>27</strong>(5), 461-479.</li>

<li><a id="her67" name="her67" />Herner, S., &amp; Herner, M. (1967). Information needs and uses in science and technology. <em>Annual Review of Information Science and Technology</em>, <strong>2</strong>, 1-34.</li>

<li><a id="ing96" name="ing96" />Ingwersen, P. (1996). Cognitive perspectives of information retrieval interaction. <em>Journal of Documentation</em>, <strong>52</strong>(1), 3-50.</li>

<li><a id="jar86" name="jar86" />J&auml;rvelin, K. (1986). On information, information technology and the development of society: an information science perspective. In P. Ingwersen, L. Kajberg,  &amp; A. Mark Pejtersen (eds.), <em>Information technology and information use: towards a unified view of information and information technology</em>. London: Taylor Graham: 35-55.</li>
<li><a id="jar87" name="jar87" />J&auml;rvelin, K. (1987). Kaksi yksinkertaista j&auml;sennyst&auml; tiedon hankinnan tutkimusta varten [Two simple conceptual frameworks for information seeking research]. <em>Kirjastotiede ja Informatiikka</em>, <strong>6</strong>(1), 18-24. [In Finnish, English abstract]</li>

<li><a id="jar83" name="jar83" />J&auml;rvelin, K. &amp; Repo, A. (1983). On the impacts of modern information technology on information needs and seeking: a framework. In H.J. Dietschmann, (Ed.), <em>Representation and exchange of knowledge as a basis of information processes</em> (pp. 207-230). Amsterdam, NL: North-Holland.</li>
<li><a id="jar84" name="jar84" />J&auml;rvelin, K. &amp; Repo, A. (1984). A taxonomy of knowledge work support tools.  <em>Proceedings of the Annual Meeting of the American Society for Information Science</em>, <strong>21</strong>, 59-62. </li>
<li><a id="ker73" name="ker73" />Kernan, J.B., &amp; Mojena, R. (1973). Information utilization and personality. <em>Journal of Communication</em>, <strong>23</strong>(3), 315-327</li>
<li><a id="kuh91" name="kuh91" />Kuhlthau, C.C. (1991). Inside the search process:  information seeking from the user's perspective. <em>Journal of the American Society for Information Science</em>, <strong>42</strong>(5): 361-371.</li>
<li><a id="kuh93" name="kuh93" />Kuhlthau, C.C. (1993). <em>Seeking meaning: a process approach to library and information services.</em> Norwood, NY: Ablex.</li>
<li><a id="mcc61" name="mcc61" />McClelland, D.C. (1961). <em>The achieving society</em>.  New York, NY: Van Nostrand,</li>
<li><a id="mac84" name="mac84" />MacMullin, S.E. &amp; Taylor, R.S. (1984). Problem dimensions and information traits. <em>The Information Society</em> <strong>3</strong>(), 91-111.</li>
<li><a id="mar67" name="mar67" />March, J. &amp; Simon, H. (1967). <em>Organizations</em>. (2nd ed.). New York, NY: Wiley. </li>
<li><a id="mur92" name="mur92" />Murtonen, K. (1992). Tuloksellisempaan tiedonhankintatutkimukseen: prosessianalyysi tiedontarpeiden ja tiedonhankinnan tutkimuksessa [Toward more effective information seeking studies: use of process-analysis in information needs and information seeking research]. <em>Kirjastotiede ja Informatiikka</em> <strong>11</strong>(2), 43-52. (In Finnish)</li>
<li><a id="mur94" name="mur94" />Murtonen, K. (1994). <em>Ammatilliset tiedontarpeet ja tiedonhankinta tutkimuskohteena: Tutkimus teht&auml;v&auml;n kompleksisuuden vaikutuksista tiedontarpeisiin ja tiedonhankintaan</em>. [Professional information needs and information seeking as study objects: a study on the effects of task complexity on information needs and information seeking]. Thesis for the Degree of Licentiate of Social Sciences. Tampere: University of Tampere, Department of Information Studies. (In Finnish)</li>
<li><a id="pal91" name="pal91" />Palmer, J. (1991). Scientists and information. II. Personal factors in information behaviour. <em>Journal of Documentation</em>, <strong>47</strong>(3), 254-275</li>

<li><a id="rob81" name="rob81" />Roberts, K.H. &amp; Glick, W. (1981). The job characteristics approach to task design: a critical review. <em>Journal of Applied Psychology</em>, <strong>66</strong>(2), 193-217.</li>

<li><a id="sar" name="sar96" />Saracevic, T. (1996).  Modeling interaction in information retrieval: a review and proposal. <em>Proceedings of the Annual Academy Meeting of American Society for Information Science</em>, <strong>33</strong>, 3-9.</li>

<li><a id="sia98" name="sia98" />Siatri, R. (1998). Information seeking in electronic environment: a comparative investigation among computer scientists in British and Greek universities. <em>Information Research</em>, <strong>4</strong>(2). Retrieved 27 September, 2003, from http://informationr.net/ir/4-2/isic/siatri.html</li>

<li><a id="spi97" name="spi97" />Spink, A. (1997).  Study of interactive feedback during mediated information 
retrieval. <em>Journal of the American Society for Information Science</em>, <strong>48</strong>(5), 382-394. 
</li>

<li><a id="tho67" name="tho67" />Thompson, J.D. (1967). <em>Organizations in action.</em> New York, NY: McGraw-Hill Book Co.</li>
<li><a id="tia92" name="tia92" />Tiamiyu, M.A. (1992). The relationships between source use and work complexity, decision-maker discretion and activity duration in Nigerian government ministries. <em>International Journal of Information Management</em>, <strong>12</strong>(2), 130-141.</li>

<li><a id="tim89" name="tim89" />Timko, M., &amp; Loynes, R.M.A. (1989). Market information needs for prairie farmers. <em>Canadian Journal of Agricultural Economics</em>, <strong>37</strong>, 609-627.</li>

<li><a id="tus78" name="tus78" />Tushman, M.L. (1978). Technical communication in R&amp;D laboratories: the impact of project work characteristics. <em>Academy of Management Journal</em>, <strong>21</strong>(4), 624-645.</li>

<li><a id="vak98" name="vak98" />Vakkari, P. (1998).  Growth of theories on information seeking. An analysis of growth of a theoretical research program on relation between task complexity and information seeking. <em>Information Processing &amp; Management</em>, <strong>34</strong>(3/4), 361-382.</li>

<li><a id="vak99" name="vak99" />Vakkari, P. (1999). Task complexity, problem structure and information actions. Integrating studies on information seeking and retrieval. <em>Information Processing &amp; Management</em>, <strong>35</strong>(6), 819-837.</li>
<li><a id="vak97" name="vak97" />Vakkari, P. &amp; Kuokkanen, M. (1997). Theory growth in information science: Applications of the theory of science to a theory of information seeking. <em>Journal of Documentation</em>, <strong>53</strong>(5), 497-519.</li>
<li><a id="van80" name="van80" />Van de Ven, A. &amp; Ferry, D. (1980). <em>Measuring and assessing organizations</em>. New York, NY: Wiley.</li>
<li><a id="wag85" name="wag85" />Wagner, D. &amp; Berger, J. (1985). Do sociological theories grow? <em>American Journal of Sociology</em>m <strong>90</strong>, 697-728.</li>
<li><a id="wil81" name="wil81" />Wilson, T.D. (1981). On user studies and information needs. <em>Journal of Documentation</em>, <strong>37</strong>(1), 3-15.</li>
<li><a id="wil97" name="wil97" />Wilson, T.D. (1997). Information behaviour: an interdisciplinary perspective. <em>Information Processing &amp; Management</em>, <strong>33</strong>(4), 551-572.</li>
<li><a id="wil99" name="wil99" />Wilson, T.D. (1999). Models in information behaviour research. <em>Journal of Documentation</em>. <strong>55</strong>(3), 249-270.</li>
<li><a id="wil80" name="wil80" />Wilson, T.D. &amp; Streatfield, D.R. (1980). <em><a href="http://informationr.net/tdw/publ/INISS/">&quot;You can observe a lot...&quot; A study of information use in local authority social services departments conducted by Project INISS</a></em> Sheffield: University of Sheffield, Postgraduate School of Librarianship and Information Science. (Occasional Publication No. 12)  Retrieved 27 September, 2003, from http://informationr.net/tdw/publ/INISS/</li>
<li><a id="woo86" name="woo86" />Wood, R.E. (1986). Task complexity: definition of the construct. <em>Organizational Behavior and Human Decision Processes</em>m <strong>37</strong>(1), 60-82.</li>
<li><a id="zef93" name="zef93" />Zeffane, R.M. &amp; Gul, F.A. (1993). The effects of task characteristics and sub-unit structure on dimensions of information processing. <em>Information Processing &amp; Management</em>. <strong>29</strong>(6): 703-719.</li>
</ul>

<hr size="3" style="color:#000080 ;" />

<h2><a id="app" name="app" />Appendix</h2>

<p>Bystr&ouml;m's (1999) eleven statements - cf. Figure 5.</p>
<p>S1: as soon as information acquisition requires an effort people as sources are more popular than documentary sources.</p>
<p>S2: the more information types are needed, the greater the share of people as sources.</p>
<p>S3: the more information types are needed, the greater the share of general-purpose sources and the smaller the share of task-oriented sources.</p>
<p>S4: the more information types are needed, the more sources are used.</p>
<p>S5: the internality of different source types is loosely connected to the information types.</p>
<p>S6: the higher the degree of task complexity, the more probable is the need for multiple information types: first task information, then task and domain information, and finally task, domain and [problem] solving information.</p>
<p>S7: the higher the degree of task complexity, the more information types are needed, and the greater the share of people as sources and the smaller the share of documentary sources.</p>
<p>S8: the higher the degree of task complexity, the more information types are needed and the greater the share of general-purpose sources and the smaller the share of task-oriented sources.</p>
<p>S9: the higher the degree of task complexity, the more information types are needed, and the higher the number of sources used.</p>
<p>S10: task complexity is distinctly related to increasing internality of people as sources and decreasing internality of documentary sources.</p>
<p>S11: Increasing task complexity fosters the use of people as sources.</p>

<hr style="COLOR: #000080" size="1" />
<table cellspacing="10" align="center">
<tr><td align="center" valign="top">
<center>
<form method="get" action="http://scholar.google.com/scholar" target="_blank">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="hidden" name="q" size="31" maxlength="255" value="&quot;conceptual models&quot;  &quot;information seeking&quot;  &quot;information retrieval&quot;"></input> <br />
<input type="submit" name="sa" value="Scholar Search"  style="font-family: Verdana; font-weight: bold;"></input>
<input type="hidden" name="num" value="100"></input>
</td></tr></table></form>
<td colspan="2" align="center" style="font-family: verdana; font-size: small; font-weight: bold;">Find other papers on this subject.</td>
</center>
<td align="center" valign="top">
<!-- Search Google -->
<center>
<form method="get" action="http://www.google.com/custom" target="_top">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="hidden" name="q" size="31" maxlength="255" value="&quot;conceptual models&quot;  &quot;information seeking&quot;  &quot;information retrieval&quot;"></input><br />
<input type="submit" name="sa" value="Google Search" style="font-family: Verdana; font-weight: bold;"></input>
<input type="hidden" name="client" value="pub-5081678983212084"></input>
<input type="hidden" name="forid" value="1"></input>
<input type="hidden" name="ie" value="ISO-8859-1"></input>
<input type="hidden" name="oe" value="ISO-8859-1"></input>
<input type="hidden" name="cof" value="GALT:#0066CC;GL:1;DIV:#999999;VLC:336633;AH:center;BGC:FFFFFF;LBGC:FF9900;ALC:0066CC;LC:0066CC;T:000000;GFNT:666666;GIMP:666666;FORID:1;"></input>
<input type="hidden" name="hl" value="en"></input>
</td></tr></table>
</form>
</center>
<!-- Search Google -->
</td></tr>
</table>

<hr style="COLOR: #000080" size="1" />
<div align="center">
<h4>How to cite this paper:</h4>
J&auml;rvelin, K. and Wilson, T.D. (2003) 
&quot;On conceptual models for information seeking and retrieval research&quot; &nbsp; <em>Information Research</em>, <strong>9</strong>(1) paper 163 [Available at http://InformationR.net/ir/9-1/paper163.html]</div>
<br />

<hr style="COLOR: #000080" size="1" />
<div align="center">Articles citing this paper, <a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=link:4xh0M3AZXJIJ:scholar.google.com/" target="_blank">according to Google Scholar</a></div>
<hr style="COLOR: #000080" size="1" />

<table align="center" cellpadding="10">
<tr><td align="center" valign="top"><div>
<img src="http://counter.digits.com/wc/-d/-z/6/-b/FF0033/paper163" align="middle"  width="60" height="20" border="0" hspace="4" vspace="2" alt="counter" /><br /><a href="http://www.digits.com/">Web Counter</a>
</div></td>

<td align="center" valign="top"><div>
&copy; the authors, 2003. <br />Last updated: 29 September, 2003</div></td>

<td align="center" valign="middle"><img src="../valid-xhtml10.gif" alt="Valid XHTML 1.0!" height="16" width="44" />
</td></tr>
</table>
<hr size="1" style="color:#000080 ;" />

<table align="center"><tr><td><div id="button">
<ul>
	<li><a href="infres91.html">Contents</a> | </li>
	<li><a href="../iraindex.html">Author index</a> | </li>
	<li><a href="../irsindex.html">Subject index</a> | </li>
	<li><a href="../search.html">Search</a> | </li>
	<li><a href="../index-2.html">Home</a></li>
</ul>
</div></td></tr></table>
<hr size="3" style="color:#000080 ;" />
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-672528-1";
urchinTracker();
</script>
</body>

<!-- Mirrored from informationr.net/ir/9-1/paper163.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:15:37 GMT -->
</html>

