<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<!-- Mirrored from informationr.net/ir/8-4/paper161.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:22 GMT -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<title>Synchronised Object Retrieval: the enhancement of  information retrieval <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in multimedia environments using synchronisation protocols</title>
<link href="../IRstyle.css" rel="stylesheet" />
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta content="<span>Microsoft</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>FrontPage 5.0" name="generator" />
<link rev="made" href="mailto:t.d.wilson@shef.ac.uk" />
<meta name="Keywords" content="information, information retrieval, synchronisation, multimedia retrieval, ynchronized Multimedia Integration <span>Language</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> SMIL" />
<meta content="The retrieval of objects from within collections of multimedia presentations poses a number of problems but also <span>offers</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>opportunities for enhancing retrieval <span>performance</span>, <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> by utilising  information about the relationships between objects. This paper is concerned with the theoretical  <span>possibility</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of using the synchronisation information <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in SMIL-compliant multimedia presentations to retrieve objects which may either <span>lack</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>appropriate metadata or where the metadata  is insufficient to enable <span>reliable</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>retrieval. It suggests that the synchronicity of display of objects could be used to infer their content and that this would provide possibilities for enhancement of retrieval <span>performance</span>. <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> It further suggests how this process might be <span>achieved</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and recommends that an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL-compliant presentations needs to be <span>established</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to enable <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work to be undertaken." name="Description" />
<meta name="rating" content="mature" />
<meta name="vw96.objecttype" content="document" />
<meta name="robots" content="all" />
<meta name="dc.title" content="Synchronised object retrieval: the enhancement of information retrieval <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in multimedia environments using synchronisation protocols" />
<meta name="dc.creator" content="Brophy, P." />
<meta name="dc.subject" content="Synchronized Multimedia Integration <span>Language</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> information, information retrieval, synchronisation, multimedia retrieval SMIL" />
<meta name="dc.<span>description</span>" <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> content="The retrieval of objects from within collections of multimedia presentations poses a number of problems but also <span>offers</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>opportunities for enhancing retrieval <span>performance</span>, <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> by utilising information about the relationships between objects. This paper is concerned with the theoretical  <span>possibility</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of using the synchronisation information <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in SMIL-compliant multimedia  presentations to retrieve objects which may either <span>lack</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>appropriate metadata or where the metadata  is insufficient to enable <span>reliable</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>retrieval. It suggests that the synchronicity of display of  objects could be used to infer their content and that this would provide possibilities for  enhancement of retrieval <span>performance</span>. <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> It further suggests how this process might be <span>achieved</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and  recommends that an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL-compliant presentations needs to be <span>established</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to enable <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work to be undertaken." />
<meta name="dc.publisher" content="<span>Professor</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>T.D. Wilson" />
<meta name="dc.coverage.placename" content="global" />
<meta name="DC.Subject.keywords" content="information, information retrieval, synchronisation, multimedia retrieval SMIL" />
<meta name="DC.Subject" content="multimedia retrieval" />
<meta name="DC.Type" content="text" />
<meta name="DC.Identifier" scheme="ISSN" content="1368-1613" />
<meta name="DC.Relation.IsPartOf" content="infres84.html" />
<meta name="DC.Format" content="text/html" />
<meta name="DC.<span>Language</span>" <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> content="en" />
<meta name="DC.Rights" content="http://creativecommons.org/licenses/by-nd-nc/1.0/" />
<script language="<span>JavaScript</span>" <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> type="text/javascript">
<!--
function MM_preloadImages() { //v3.0
  var d=document; if(d.images){ if(!d.MM_p) d.MM_p=new Array();
    var i,j=d.MM_p.<span>length</span>, <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>a=MM_preloadImages.arguments; for(i=0; i<a.length; i++)
    if (a[i].indexOf("#")!=0){ d.MM_p[j]=new Image; d.MM_p[j++].src=a[i];}}
}

function MM_findObj(n, d) { //v4.01
  var p,i,x;  if(!d) d=document; if((p=n.indexOf("?"))>0&&parent.frames.length) {
    d=parent.frames[n.substring(p+1)].document; n=n.substring(0,p);}
  if(!(x=d[n])&&d.all) x=d.all[n]; for (i=0;!x&&i<d.forms.length;i++) x=d.forms[i][n];
  for(i=0;!x&&d.layers&&i<d.layers.length;i++) x=MM_findObj(n,d.layers[i].document);
  if(!x && d.getElementById) x=d.getElementById(n); return x;
}

function MM_nbGroup(event, grpName) { //v6.0
  var i,img,nbArr,args=MM_nbGroup.arguments;
  if (event == "init" && args.<span>length</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>> 2) {
    if ((img = MM_findObj(args[2])) != null && !img.MM_init) {
      img.MM_init = true; img.MM_up = args[3]; img.MM_dn = img.src;
      if ((nbArr = document[grpName]) == null) nbArr = document[grpName] = new Array();
      nbArr[nbArr.length] = img;
      for (i=4; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
        if (!img.MM_up) img.MM_up = img.src;
        img.src = img.MM_dn = args[i+1];
        nbArr[nbArr.length] = img;
    } }
  } else if (event == "over") {
    document.MM_nbOver = nbArr = new Array();
    for (i=1; i < args.length-1; i+=3) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = (img.MM_dn && args[i+2]) ? args[i+2] : ((args[i+1])? args[i+1] : img.MM_up);
      nbArr[nbArr.length] = img;
    }
  } else if (event == "out" ) {
    for (i=0; i < document.MM_nbOver.length; i++) {
      img = document.MM_nbOver[i]; img.src = (img.MM_dn) ? img.MM_dn : img.MM_up; }
  } else if (event == "down") {
    nbArr = document[grpName];
    if (nbArr)
      for (i=0; i < nbArr.length; i++) { img=nbArr[i]; img.src = img.MM_up; img.MM_dn = 0; }
    document[grpName] = nbArr = new Array();
    for (i=2; i < args.length-1; i+=2) if ((img = MM_findObj(args[i])) != null) {
      if (!img.MM_up) img.MM_up = img.src;
      img.src = img.MM_dn = (args[i+1])? args[i+1] : img.MM_up;
      nbArr[nbArr.length] = img;
  } }
}
//-->
</script>
<link href="http://localhost/TEXTY/css/parser.css" rel="stylesheet" type="text/css" /></head>

<body  bgcolor="#ffffff" onload="MM_preloadImages('../figs/iauthori1.gif','../figs/isubji1.gif','../figs/isearch1.gif','../figs/ihome1.gif','../figs/contents1.gif')">
<table align="center" border="0" cellpadding="0" cellspacing="0">
<tr><td height="30" align="center" colspan="5"><h4>Information Research, Vol. 8  No. 4, July 2003</h4></td></tr>
  <tr> 
    <td><a href="infres84.html" target="_top" onclick="MM_nbGroup('down','group1','contents','',1)" onmouseover="MM_nbGroup('over','contents','../figs/contents1.gif','',1)" onmouseout="MM_nbGroup('out')"><img src="../figs/contents.gif" alt="contents" name="contents" border="0" id="contents"  /></a></td>
    <td><a href="../iraindex.html" target="_top" onclick="MM_nbGroup('down','group1','authorindex','',1)" onmouseover="MM_nbGroup('over','authorindex','../figs/iauthori1.gif','',1)" onmouseout="MM_nbGroup('out')"><img src="../figs/iauthori.gif" alt="auindex" name="authorindex" width="120" height="20" border="0" id="authorindex" /></a></td>
    <td><a href="../irsindex.html" target="_top" onclick="MM_nbGroup('down','group1','subjindex','',1)" onmouseover="MM_nbGroup('over','subjindex','../figs/isubji1.gif','',1)" onmouseout="MM_nbGroup('out')"><img src="../figs/isubji.gif" alt="subindex" name="subjindex" width="120" height="20" border="0" id="subjindex" /></a></td>
    <td><a href="../search.html" target="_top" onclick="MM_nbGroup('down','group1','search','',1)" onmouseover="MM_nbGroup('over','search','../figs/isearch1.gif','',1)" onmouseout="MM_nbGroup('out')"><img src="../figs/isearch.gif" alt="<span>search</span>" <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> name="<span>search</span>" <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> width="120" height="20" border="0" id="<span>search</span>" <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> /></a></td>
    <td><a href="../index.html" target="_top" onclick="MM_nbGroup('down','group1','home','',1)" onmouseover="MM_nbGroup('over','home','../figs/ihome1.gif','',1)" onmouseout="MM_nbGroup('out')"><img src="../figs/ihome.gif" alt="home" name="home" border="0" id="home" /></a></td>
  </tr>
</table>
<hr size="3" style="color:#000080 ;" />
<h1>Synchronised Object Retrieval: the enhancement of  information retrieval <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in multimedia environments using synchronisation protocols</h1>

<h4 align="center"><a href="mailto:p.brophy@mmu.ac.uk">Peter Brophy</a><br />
  Centre for Research in Library and Information Management<br />
  Department of Information and Communications<br />
  Manchester Metropolitan University<br />
  Manchester, UK</h4>
<br />

<div align="center"><b>Abstract</b></div>

<blockquote>The retrieval of objects from within collections of multimedia presentations poses a 
number of problems but also <span>offers</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>opportunities for enhancing retrieval <span>performance</span>, <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> by utilising
 information about the relationships between objects. This paper is concerned with the theoretical 
 <span>possibility</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of using the synchronisation information <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in SMIL-compliant multimedia 
 presentations to retrieve objects which may either <span>lack</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>appropriate metadata or where the metadata 
 is insufficient to enable <span>reliable</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>retrieval. It suggests that the synchronicity of display of 
 objects could be used to infer their content and that this would provide possibilities for 
 enhancement of retrieval <span>performance</span>. <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> It further suggests how this process might be <span>achieved</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and 
 recommends that an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL-compliant presentations needs to be <span>established</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>
 to enable <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work to be undertaken.</blockquote>
 
<br />
 
<h2>Introduction</h2>

<p>One of the <span>roles</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of a research centre is to engage in speculative enquiry which may increase 
understanding of existing or <span>future</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>systems</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>or open up possible new avenues of enquiry. This paper 
is concerned with one such exploratory study undertaken by CERLIM (the Centre for Research in Library 
and Information Management at the Manchester Metropolitan University) from 1999 to 2002. The study in 
question arose from observations of a variety of <span>separate</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>research and development projects in the 
digital library and information retrieval area (including CERLIM's <a href="http://www.cerlim.ac.uk/projects/reviel.html">REVIEL</a> and <a href="http://www.cerlim.ac.uk/edner/welcome.html">EDNER</a> projects),  and concerned the question of how information objects expressed in a variety of media and perhaps embedded in multimedia presentations might be brought to the <span>attention</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of end users. An obvious example would be an image or audio file which had been published as part of a complex multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>but which might contain information of relevance to a wide <span>range</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of users who were not primarily interested in the complex object itself. An example might be a multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>on the Kalahari desert which incidentally <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>an image of  a sunset. How might an end user compiling a <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>on sunsets find such an embedded image?</p>

<p>While the example above may appear trivial, it illustrates what is likely to be a <span>growing</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>problem, <span>namely</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>that information objects will increasingly be 'packaged' in ways that make them invisible to standard methods of retrieval. Are there potential ways of addressing this problem in real world scenarios which do not simply involve the well-nigh <span>impossible</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>– and <span>probably</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>unacceptable to rights-holders – task of creating vast new datasets of disaggregated objects?</p>

<p>One approach, which has intriguing possibilities, would be to exploit the existence of documented 
relationships within complex objects. The most useful part of such documentation might be the information 
which is created to control the display of the complex object on the client workstation. In particular, 
it might be feasible to use information <span>designed</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to enable the streamed delivery of multimedia across 
the Internet for the enhancement of retrieval. The <span>major</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>problem with this type of delivery is that 
it cannot be taken for granted that each element of the <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>will arrive at the workstation 
when required. For example, because of <span>network</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>bandwidth or other limitations, it may be that a video 
track will be delayed while the accompanying audio arrives unhindered. Clearly, it would be 
unsatisfactory simply to play the audio and later, when it arrives, the video. To overcome this 
problem, the <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>includes a synchronisation track which not only tells the client the order 
in which to play individual components but contains check-points and other instructions on how to 
handle delayed or missing files.</p>

<p>One of the leading standards for synchronisation is called SMIL, the Synchronized Multimedia 
Integration <span>Language</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> which is pronounced 'smile' (<a href="#WWWC">World Wide Web Consortium, 2000</a>). This <span>formed</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the <span>environment</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>for a feasibility study, carried out with funding from the UK's <a href="http://www.resource.gov.uk/">Re:source, the Council for Museums, Archives and Libraries.</a> This paper presents the <span>findings</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of both that study (the Final Report is available online: <a href="#Brophy">Brophy, <em>et al.</em>, 2000</a>) and <span>subsequent</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work to examine the ways SMIL is being implemented. Sample SMIL presentations and a tutorial are available online from <a href="http://www.realnetworks.com/resources/samples/smilbasics.html">
RealNetworks</a>.</p>

<p>While for the <span>purposes</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the study reported here it was deemed useful to explore multimedia 
objects with explicit relationship coding, in principle there is no reason to suppose that the broad 
approach would not be more widely applicable. For example, it might be used to enhance retrieval of 
objects embedded in PowerPoint presentations by making an <span>assumption</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>that the individual slide itself 
signifies that a relationship exists between the different objects it contains.</p>

<h2>The concept of Synchronised Object Retrieval</h2>

<p>Because SMIL defines temporal and other relationships between objects within a multimedia <span>presentation</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> it should be possible to extract retrieval clues from the simultaneity of playback of constituent 'micro-objects'. The <span>term</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>'micro-object' is used here to describe any mono-media file which is a component of a multimedia <span>presentation</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> For example, if it is known that a text file is to be played back at the same time as an image file, and a text-based <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the text file retrieves relevant keywords, then if the same query expressed as a content-based <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the image file also <span>produces</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>possible matches, the <span>inference</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>can be <span>drawn</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>that</p>

<ul>
  <li>the multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>as a whole has relevance to the query</li>
  <li>the instance identified (i.e. the simultaneous display of the text and image files) has relevance</li>
  <li>the text file has relevance</li>
  <li>the image file has relevance</li>
</ul>

<p>and each of these conclusions may be <span>drawn</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>with a higher <span>degree</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of confidence than a simple 
<span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of any one component part of the multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>could produce. In other words, 
the known synchrony of the files allows reinforcement of retrieval conclusions. We have termed 
this concept Synchronised Object Retrieval (SOR).</p>

<p>It is suggested that the SOR approach could be used either</p>

<ul>
  <li>to enable the retrieval of individual micro-objects from within multimedia presentations across
   collections of heterogeneous multimedia presentations, or</li>
  <li>to enable the retrieval of multimedia presentations from one or more <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of such 
  presentations, by examining the results of searching across some or all of a <span>presentation</span>' <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>s 
  constituent micro-objects.</li>
</ul>

<p>There are many possible <span>applications</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of such capability – an example would be that of a lecturer searching across a large <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of multimedia learning objects to find micro-objects to re-use in a new <span>presentation</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<p>In essence a SOR system would need to examine each multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to determine its content, which might be expressed explicitly in metadata associated either with the complex object or with each micro-object or might be inferred by, for example, content-based image retrieval. The relationship between objects then needs to be examined to infer degrees of relevance.</p>

<p>As far as we have been able to determine the only related research in this area is that reported by 
Little, <em>et al.</em> where the objective is the dynamic generation of SMIL presentations by examining metadata and inferring <strong>semantic</strong> relationships. Temporal relationships in this work refer to, for example, dates of publication or of the life of a 'subject' or 'creator' of an object, not to temporal relationships in the display of the presentation:</p>

<blockquote>Using the Open Archive Initiative (OAI) as a testbed, we have developed a service which uses the Dublin Core metadata published by the OAI data providers, to infer <span>semantic</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>relations between mixed-media objects distributed across the archives. Using predefined <span>mapping</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>rules, these <span>semantic</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>relationships are then mapped to spatial and temporal relationships between the objects.... Our premise is that by using automated <span>computer</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>processing of metadata to organize and combine semantically-related objects within multimedia presentations, the system may be able to generate new knowledge, not explicitly recorded, by inferring and exposing previously unrecognized <span>connections</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>  (Little, <em>et al.</em> <a href="#Little">2002</a>) </blockquote>

<p>With large collections of multimedia presentations a SOR system would <span>require</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>a very high level of computing power. While in the past this may have been a <span>reasonable</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>objection to the SOR approach, the effects of <a href="http://www.intel.com/research/silicon/mooreslaw.htm">Moore's Law</a>, which posits the 
inexorable doubling of computing power every eighteen to twenty-four months, suggests that computing power may not be an issue in the future; although recent commentary (e.g., <a href="#Tweney">Tweney, 2002</a>) has questioned whether this trend will continue. However, while this may be the case in theoretical terms, it seems unlikely that computing costs for large-scale retrieval <span>systems</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>will not continue to <span>fall</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> or power per unit of expenditure increase for some time. Arms (<a href="#Arms">2000</a>) has made the observation that 'simple <span>algorithms</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>plus immense computing power often outperform human intelligence' and points out that processes which in the past would have been unthinkable are now routine, using the example of the Google Internet <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>engine:</p>

<blockquote>Evaluating the importance of <span>documents</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>would appear to be a task that <span>requires</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>human understanding, but Google's ranking <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>does remarkably well entirely automatically…  Calculating the ranks <span>requires</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to iterate through a matrix that has as many rows and columns as there are pages on the web, yet with <span>modern</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>computing and <span>con0erable</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>ingenuity, Google performs this <span>calculation</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>routinely.</blockquote>

<h2>SMIL - the Synchronized Multimedia Integration Language</h2>

<p>The Synchronized Multimedia Integration <span>Language</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>or SMIL standard is based on <span>XML</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>(<a href="http://www.w3.org/XML/">the eXtensible Markup Language</a>) and its syntax is defined in an <span>XML</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>DTD (document type definition). It is an official World Wide Web Consortium (W3C) standard. SMIL <span>documents</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>can be authored using a simple text editor, since they are in essence similar to <span>HTML</span>, <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> although a variety of SMIL-enabled authoring <span>tools</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>are available. The project team <span>investigated</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>these and used the <a href="http://www.creativepro.com/software/home/1367.html">RealSlideshow Plus</a> package as a basis for exploring the potential of SMIL. <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>demonstration SMIL application was developed during the study by CERLIM staff using this tool.</p>

<p>As part of the study the team undertook a <span>detailed</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>evaluation of mainly web-based resources relevant to SMIL. Because the concept being explored would <span>require</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>familiarity with recent research in text, audio, video and other media retrieval, a wide-ranging literature review was also undertaken and this has been reported elsewhere (<a href="#Hartley">Hartley, <em>et al.</em> 2000)</a>.</p>

<p>The SMIL standard defines a number of different types of media micro-objects that can be included in a <span>presentation</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<ul>
  <li>animation: animated vector graphics or other animated format </li>
  <li>audio: audio clip </li>
  <li>img: still image </li>
  <li>text: text <span>reference</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></li>
  <li>textstream: streaming text </li>
  <li>video: video clip </li>
  <li>ref: generic media <span>reference</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>(in effect, 'other')</li>
</ul>

<p>For example, an author can write synchronisation instructions such as: 'play audio file <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in <span>parallel</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>with video file B' and 'display text file C after audio file <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and in <span>parallel</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>with animation file D and with text stream E'. In addition SMIL enables the author to define the positioning of micro-objects on the user's screen (or 'visual rendering surface' in the <span>terminology</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the standard). Various other variables can be used, such as the ability to <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the end-user's bandwidth and deliver alternative micro-objects accordingly. However, these <span>features</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>are unlikely to be of <span>major</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>significance in the context of an information retrieval system.</p>

<p>One of the advantages of the SMIL approach is that it effectively enables objects which would normally <span>require</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>high-bandwidth, such as multimedia presentations, to be delivered across low-bandwidth networks since each constituent micro-object  can be transmitted separately and the <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>correctly reassembled and played at the client end, using the synchronisation information. It thus has enormous potential for the <span>distribution</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of all <span>kinds</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of multimedia objects. <span>Furthermore</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> there is no reason why the micro-objects cannot be repackaged and delivered within <span>separate</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>presentations, without the expense of re-recording a video or other complex element as might be the case were the <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to be recorded as a single file of data. Among other useful aspects of the approach is the use of alternative files: for example, a commentary can be stored in a variety of <span>languages</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and the user given the option as to which should be played, or the option can be picked up automatically from the user's preference settings. SMIL 2.0 (the current standard) has <span>introduced</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the concepts of modularisation and profiling to enable functionality to be <span>extended</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and the <span>integration</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of related mark-up <span>languages</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<h2>SMIL and information retrieval</h2>

<p>While SMIL has not been <span>designed</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>with information retrieval (IR) <span>applications</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in mind, the schema does contain some explicit IR-related <span>features</span>, <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> most notably the provision of metadata fields at both object and micro-object levels. Thus, the standard defines a <a href="http://www.w3.org/RDF/">Resource Description Framework</a> (RDF) compliant 'metainformation' module which should enable the macro-object and its constituent micro-objects to be retrieved in the same way as any other <span>documents</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>by examining metadata elements. While the schema used is open, the SMIL 2.0 standard <span>suggest</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the use of <a href="http://dublincore.org/">Dublin Core</a> (DC) as a generalised approach and an example of this usage can be found in section 8.5 of the standard. In addition to, say, subject-based retrieval, using the DC  subject, title and <span>description</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>elements for instance, a SOR system could use some elements to refine <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>results. Using the DC 'creator' element to find micro-objects which were created by the same <span>person</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>so as to infer some commonality might be an example of this approach. There is also a field <span>intended</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>for content rating metadata, such as the <a href="http://www.w3.org/PICS/">Platform for Internet Content Selection (PICS)</a>, which, in some circumstances, might be a useful aid to retrieval.</p>

<p>However a <span>difficulty</span>, <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> as our later investigations showed, is that subject metadata fields are <span>frequently</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>unused by multimedia producers, especially at the micro-object level, or where they are used there is no meaningful <span>vocabulary</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>control. Thus while these fields would be examined in any real-life SOR application, it is to other <span>features</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL that developers would need to look. Among those relevant to IR are:</p>

<ul>
  <li>SMIL supports the inclusion of linked objects in a <span>presentation</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> through its Linking Module, enabling events 
such as a user clicking on an area of the screen, to trigger a link to another part of the <span>presentation</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> As in <span>HTML</span>, <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>  provision is made for supporting name fragment identifiers, by using the # <span>symbol</span>, <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> to enable a link to be made to any tagged element within a micro-object.  For example, if the SMIL 2.0 documentation was itself part of a SMIL <span>presentation</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> a link could be provided to http://www.w3.org/TR/smil20/extended-media-object.html#edef-ref where <span>definitions</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of media object elements would be found. If this is not the start of the micro-object the effect would be as if the user had fast-forwarded within that object to a specified place. Further refinement is possible: for example, SMIL contains provision to enable the author to specify precedence levels for cases where the <span>origin</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and linked objects continue to play simultaneously - an example would be <span>setting</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the relative audio playback levels. Again, although we did not explore these in detail in the feasibility study, it would be possible for <span>software</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to follow embedded <span>links</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and to take account of associated variables to retrieve further micro-objects which may themselves contain both usable metadata and other retrieval clues.</li>

  <li>The SMIL 2.0 standard has specified various <span>features</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>intended to improve accessibility, especially for people with <span>visual</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>or other disabilities. For example a 'long <span>description</span>' <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> <span>attribute</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>enables the author to provide a long text <span>description</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> <span>separate</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>from the metadata fields, which could be very useful for enhancing retrieval. Because of the ability to define user-required variants it is also possible to allow for the identification of, for example, text equivalents of audio <span>intended</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>for closed-captioning, thus providing a further accessibility <span>feature</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and additional IR possibilities. </li>

  <li>As noted above, a 'language' <span>attribute</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>is available, <span>intended</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>for presentations where the user has <span>choice</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of, say, a French, German or <span>English</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>sound track: the multimedia <span>presentation</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> of course. would contain three files, each synchronised with the video and other elements. Again, the possibilities for enriching IR capability, by combining searches in a variety of <span>languages</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> are intriguing. </li>
</ul>

<p>Finally, it should be noted that some <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work has been carried out on the building of SMIL compliant multimedia archives from the <span>perspective</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of metadata <strong>creation</strong> (<a href="#Hunter">Hunter and Little, 2001</a>) although this does not address the use of relationships between micro-objects for retrieval.</p>

<h2>Experimental Design</h2>

<p>Although the CERLIM team has not yet developed the SOR concept beyond con0eration of feasibility, initial work has been carried out to define the requirements for <span>moving</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the SOR concept into an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>stage. We believe that the elements described in the following sub-sections would be required.</p>

<h3>Establishment of <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>collection</h3>

<p>It will be necessary to <span>establish</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>a reasonably-sized <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL-compliant multimedia presentations, showing a <span>degree</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of heterogeneity in structure and micro-object <span>composition</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> so as to challenge <span>applications</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> Despite examing a number of <span>applications</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>we have not been able to identify a <span>suitable</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>collection of SMIL-compliant objects at the present time, although the work of Little, <em>et al.</em> <span>referred</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to above must be noted. We also note that some candidate collections are restricted by IPR con0erations.</p>

<p>It will be necessary to <span>establish</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>a <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>along the <span>lines</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of <a href="http://trec.nist.gov/">TREC</a>, the Text Retrieval Conference. In order to <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the SOR approach thoroughly in <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>conditions, a carefully <span>designed</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>would be needed. In other words, it would be <span>essential</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to put effort into ensuring that the <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>displayed examples of all the different elements on which retrieval could be based, but with special <span>emphasis</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>on syncronicity. Thus, not only would examples of objects with comprehensive metadata  at the object and micro-object levels be needed, but care would need to be taken to ensure that the different media used <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>retrievable content, the attributes of which were known, in order that <span>testing</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of <span>software</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and <span>algorithms</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>could take place.</p>

<p>Because of the complexities <span>inherent</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in the SOR approach, our <span>conclusion</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>is that a <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>should be domain-limited initially. For example, the use of a <span>domain</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>such as, say, the music of a specific composer or a specific locality's history and culture would avoid the worst trans-domain <span>semantic</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and other problems. The examples that Little, <em>et al.</em> (<a href="#little">2002</a>) provide in their paper also show this concentration on a specific <span>domain</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<p>The development of a <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>would be a challenging piece of work in its own right, but would be an <span>essential</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>first step to the establishment of an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>programme. It would be helpful to consult with the TREC team in defining this <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and it may be that the <a href="http://www-nlpir.nist.gov/projects/t01v/">TREC video track</a> would form a good starting point.</p>

<p>It is perhaps <span>worth</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>noting here that although the <span>test</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>would need to be carefully crafted, this does not mean that it would have to be entirely artificial. There would be merit in identifying a nascent, real-life <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>which could be SMIL-enabled, not least because <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>work could then contribute to the solution of real-world problems and real-world queries could inform the evaluation of retrieval.</p>

<h3>User queries</h3>

<p>The analysis of the user query into mono-media components will itself be a complex process. Although in theory this could be automated, so that <span>software</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>converted a query expressed, let us say, as a text string ('Find something about the sun') into a series of media specific queries ('sun' [text]; 'sun' [audio wave file, retrieved from a 'thesaurus']; 'sun' [image <span>description</span>, <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>'round yellow object on blue background', retrieved from another 'thesaurus']; and so on), in practice this is currently impractical  or at least a different area for research. In practice it may be feasible to generate a multi-media query by providing the user with an interface which enabled descriptions to be selected/entered in a series of 'channels' e.g. text box, select from image thumbnails to find 'things like', audio input terms and so on, although the problem of segmenting and recognising audio-based queries is non-trivial, and non-verbal audio, the sound of waves breaking on a beach, for example, poses even greater problems than speech.</p>

<p>It would be possible to make user input an iterative process by presenting to the user examples of retrieval terms, especially where non-textual retrieval was being undertaken. Thus, to extend the above example, an initial user query for an image of the sun might result in a series of thumbnails, extracted by <span>reference</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to a thesaurus, being displayed and the user being invited to select from them or rank them in order of relevance. This additional user input could also be used to enable the system to learn from <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>preferences and possibly provide personalisation of results, although again this would be beyond the scope of the initial <span>experiment</span>. <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<p>As part of the feasibility study we developed a mock-up of the type of user interface we have in mind. This is shown in Fig. 1.</p> <div align="center"><img src="p161fig1.gif" alt="fig1" width="519" height="803" border="0" /></div>

<div align="center"><strong>Figure 1: Mock-up of a user interface</strong></div>

<h3>Query Analysis</h3>

<p>The user query is analysed into query <span>statements</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>capable of being applied within specific mono-media <span>contexts</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>as discussed above. So, for example, the query might be expressed as a series of text strings, some 
of which might be derived from speech, for matching against a text file, as a voice/sound wave format for matching against an audio file and so on. <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>later project might examine how, for example, text strings might be applied to an <span>intermediate</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>image thesaurus to create image queries not present in the original input data. As indicated above a possible way to use such query enhancement would be to display a set of images to the user and invite <span>selection</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the nearest matches. Again, we would expect this phase of work to draw on and be <span>influenced</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>by a <span>range</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of research, especially in the content-based information retrieval (CBIR) field.</p>

<h3>Search of presentations</h3>

<p>The first process should consist of a <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the metadata associated with each multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> as a whole. <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>ranking of objects in the <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>could be <span>achieved</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in this way, although it would be important not to discard presentations with apparent <span>zero</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>relevance from this process, since many objects may <span>lack</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>metadata and much presentation-level metadata may be irrelevant to specific component micro-objects.  An example of this could be a <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>designed to illustrate a geographical area which <span>contained</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>images of flora and fauna of the <span>region</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>but described merely by geographical location – the metadata would <span>probably</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>produce a 'zero relevance' result for a query for a particular plant or animal even if they were in fact <span>represented</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in micro-objects.</p>

<p>This process leads to a score 'A' being computed for each <span>presentation</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> As with other searches, this stage is <span>intended</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to reveal clues, not to stand on its own as a retrieval process. Where some presentations do not have associated metadata it would be appropriate to provide a <span>neutral</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>score.</p>

<h3>Search of micro-objects' metadata</h3>

<p>The <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of the micro-objects themselves could be carried out in a number of ways. For simplicity we <span>suggest</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>that the first step should be to check all micro-objects for embedded metadata, to <span>search</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>on this and to rank micro-objects for relevance accordingly. Again, many micro-objects will <span>lack</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>metadata so again all that is produced is a set of clues to relevance. This process allows a score Bx to be computed, where x is the micro-object sequential number. It should be noted that micro-objects may be regarded as being in any order for this purpose, provided only that they can be processed sequentially. Thus it may be appropriate to treat them as sequenced by filename, by file type, by 'running order' or in a variety of other ways. To avoid micro-objects without metadata being given the lowest scores it would again be appropriate to <span>calculate</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>a mean score for all micro-objects which have metadata and use this to ensure that metadata-less micro-objects score neutrally. It would of course be necessary to identify the most appropriate scoring model for the purpose.</p>

 <h3>Search of micro-objects' content</h3>
 
<p>Here we reach the core of the approach. We <span>assume</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>here that the aim is to retrieve micro-objects, although the process of retrieving presentations is similar, requiring only a method for combining the retrieval scores of constituent micro-objects. The process might take the following base model:</p>

<ol>
  <li>The synchronisation file is analysed to identify the first micro-object – note again that 'first' here is arbitrarily defined, simply implying that there is some ordering which ensures that each micro-object will be examined in <span>sequence</span>. <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> The media type should be defined in the SMIL type <span>attribute</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and this should be used to determine the type of retrieval process to be engaged. Using this process, micro-object 1 is examined, using a retrieval method other than examining metadata, as this has already been undertaken, and a score C1 computed. Again, the establishment of a scoring <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>would be an important part of the <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>research.</li>
  <li>Micro-objects which are due to be played simultaneously with the first object (this should be interpreted as meaning that there is some temporal overlap, not that they start and end at the same time) are then examined against whatever media retrieval process is appropriate. The results of each analysis are used to modify C1, producing D1: again we have not defined the <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to be used, although it may be noted that different media types might be weighted differently if it was found that, say, text retrieval produced more <span>reliable</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>results that content-based image retrieval. The effect of this stage is that C1 is increased whenever a high <span>probability</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of a match in a micro-object due for simultaneous play is identified.</li>
  <li>When micro-object 1 and all other micro-objects with which it shares some temporal space have been processed, the next micro-object in the <span>sequence</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>is examined and steps 1 and 2 repeated, providing scores D2, D3, D4 ……….. Dn.   It should be noted that because the synchrony is defined for each micro-object, it will be necessary to use the relevance score for each multiple times – clearly it will be more efficient to store these and re-use them during the process than to recompute them.</li>
  <li>At the end of the object analysis a relevance score for each micro-object is available. This is combined 
  - again, experimentation will be needed to <span>establish</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to be used - with the overall score <span>A+</span>  <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>and the  metadata score Bn to produce a 'final' score for each micro-object, En. </li>
  <li>When all objects in the <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>have been analysed, the micro-object scores En can be ranked to <span>indicate</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the most likely matches overall. These micro-objects can then be displayed to the user.</li>
</ol>

<p>Where the object is to retrieve multimedia presentations rather than micro-objects, clearly a score for each macro-object can be computed by combining - again with a <span>suitable</span>, <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> yet to be defined, <span>algorithm</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>- the scores for all constituent micro-objects and then ranking the overall score against those for other presentations.</p>

<h2>Conclusions</h2>

<p>The examination of the SMIL standard and its application described in this paper demonstrates that even in the absence of explicit metadata, or where the <span>quality</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of available metadata is poor, it should be possible to develop <span>systems</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>which use information on the relationships between micro-objects to achieve enhanced retrieval <span>performance</span>. <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> The standard also contains <span>features</span>, <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> such as those <span>intended</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>to improve accessibility, which should be explored from a retrieval <span>perspective</span>. <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span></p>

<p>It is suggested that the next stage of research should involve the development of a <span>suitable</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>test <span>collection</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of SMIL-compliant material and the establishment of an <span>experimental</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>programme to enable the ideas explored in outline in the feasibility study to be subjected to in-depth research and development. It is the intention of CERLIM to pursue funding to enable these programmes of research to be <span>established</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>as soon as possible.</p>

<p>It is clear from our research that SOR has enormous potential for application in networked information environments <span>containing</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>heterogeneous collections of multimedia presentations. As such environments proliferate, as the number of multimedia presentations mushrooms and as the cost of computing power reduces, it is to be <span>expected</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>that SOR <span>approaches</span>  <span class="quali" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>will <span>prove</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>ever more valuable.</p>

<h2>Acknowledgements</h2>

<p>The author wishes to acknowledge the <span>contributions</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>of many colleagues in CERLIM and the Department of Information and Communications to this work. Particular thanks are due to the <span>late</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>Tony Oulton, who undertook much of the background literature review, and to Richard Eskins who set up SMIL demonstrators and <span>designed</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>the mock-up of a query entry page which is illustrated here in <span>Figure</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>1.</p>

<h2>References</h2>
<ul>
  <li><a name="Arms"></a>Arms, W.Y. (2000) <a href="http://webdoc.gwdg.de/edo/d-lib/dlib/july00/arms/07arms.html">Automated digital libraries: how effectively can computers be used for the skilled tasks of professional librarianship?</a> <em>D-Lib Magazine</em>, <strong>6</strong>(7/8)  <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>10 February 2003 from   http://webdoc.gwdg.de/edo/d-lib/dlib/july00/arms/07arms.html</li>
  
  <li><a name="Brophy"></a>Brophy, P., Eskins, <span>R++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> and Oulton, T. (2000) <em><a href="http://www.cerlim.ac.uk/projects/synchro/finalv2.pdf">Synchronised Object Retrieval: a feasibility study into enhanced   information retrieval in multimedia environments using synchronisation protocols</a></em> Manchester: Centre for Research in Library &amp; Information Management.  (Library and Information Commission Research Report 92)  <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>17 July 2003 from http://www.cerlim.ac.uk/projects/synchro/finalv2.pdf</li>

  <li><a name="Hartley"></a>Hartley, <span>R++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span><span>J++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>,  Johnson, F.<span>J++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> and Oulton, <span>A+</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>J. (2000) Image, audio, text: a review of recent research in information retrieval. <em>The New Review of Information and Library Research.</em> <strong>6</strong>, 171-206. </li>

  <li><a name="Hunter"></a>Hunter, <span>J++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> and Little, S. (2001) <a href="http://archive.dstc.edu.au/RDU/staff/jane-hunter/ECDL01/ECDL01.html">Building and indexing a distributed multimedia <span>presentation</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>archive using SMIL.</a>  In: P. Constantopoulos and I.T. Solvberg <em>eds.</em> <em>Research and <span>advanced</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>technology for digital libraries.  5th European Conference, ECDL 2001, Darmstadt, <span>Germany</span>, <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> September 4-9, 2001. Proceedings.</em> (pp. 415-428) Heidelberg: Springer Verlag.  <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>17 July 2003 from 
http://archive.dstc.edu.au/RDU/staff/jane-hunter/ECDL01/ECDL01.html</li>

  <li><a name="Little"></a>Little, S., Guerts, <span>J++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> and Hunter, <span>J++</span>. <span class="compus" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span> (2002) <a href="http://archive.dstc.edu.au/maenad/ecdl2002/ecdl2002.html">Dynamic generation of intelligent multimedia presentations through <span>semantic</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>inferencing</a>.   In: M. Agosti and C. Thanos, <em>eds.</em>  <em>Research and <span>advanced</span>  <span class="quanti" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>technology for digital libraries.  6th European Conference, ECDL 2002, Rome, Italy, September 16-18, 2002. Proceedings.</em> (pp. 158-189). Heidelberg: Springer Verlag.  <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>26 May 2003 from http://archive.dstc.edu.au/maenad/ecdl2002/ecdl2002.html </li>

<li><a name="Tweney"></a>Tweney, D. (2002) <a href="http://dylan.tweney.com/writing.php?display=331">Does Moore's <span>Law</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>still <span>hold</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>true?</a> [Originally published in <em>Business 2.0</em>]  <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>17 July 2003 from http://dylan.tweney.com/writing.php?display=331 </li>

  <li><a name="WWWC"></a>World Wide Web Consortium (2000) <em><a href="http://www.w3.org/TR/smil20/">Synchronized Multimedia Integration <span>Language</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>(SMIL 2.0) specification.</a></em>  Cambridge, MA: World Wide Web Consortium. <span>Retrieved</span>  <span class="conce" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>20 May 2003 from http://www.w3.org/TR/smil20/</li>

</ul>
<hr style="COLOR: #000080" size="1" />
<table cellspacing="10" align="center">
<tr><td colspan="2" align="center" style="font-family: verdana; font-size: small; font-weight: bold;">Find other papers on this subject.<br /></td></tr>
<tr><td align="center" valign="top">
<center>
<form method="get" action="http://scholar.google.com/scholar" target="_blank">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="text" name="q" size="31" maxlength="255" value="&quot;information retrieval&quot; <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>multimedia" style="background-color: Yellow;" /></input> <br />
<input type="submit" name="sa" value="Scholar Search"  style="font-family: Verdana; font-weight: bold;" /></input>
<input type="hidden" name="num" value="100" /></input>
</td></tr></table></form>
</center>
<td align="center" valign="top">
<!-- Search Google -->
<center>
<form method="get" action="http://www.google.com/custom" target="_top">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="text" name="q" size="31" maxlength="255" value="&quot;information retrieval&quot; <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>multimedia" style="background-color: Yellow;"></input><br />
<input type="submit" name="sa" value="Google Search" style="font-family: Verdana; font-weight: bold;" /></input>
<input type="hidden" name="client" value="pub-5081678983212084"></input>
<input type="hidden" name="forid" value="1"></input>
<input type="hidden" name="ie" value="ISO-8859-1"></input>
<input type="hidden" name="oe" value="ISO-8859-1"></input>
<input type="hidden" name="cof" value="GALT:#0066CC;GL:1;DIV:#999999;VLC:336633;AH:center;BGC:FFFFFF;LBGC:FF9900;ALC:0066CC;LC:0066CC;T:000000;GFNT:666666;GIMP:666666;FORID:1;"></input>
<input type="hidden" name="hl" value="en"></input>
</td></tr></table>
</form>
</center>
<!-- Search Google -->
</td></tr>
</table>

<hr style="COLOR: #000080" size="1" />
<div align="center">
<h4>How to cite this paper:</h4>
Brophy, P. (2003) 
&quot;Synchronised Object Retrieval: the enhancement of  information retrieval <span>performance</span>  <span class="exper" style="width:1px;border-width:81px 27px 81px 27px;position:relative;">.</span>in multimedia environments using synchronisation protocols.&quot; &nbsp; <em>Information Research</em>, <strong>8</strong>(4) paper 161 [Available at http://InformationR.net/ir/8-4/paper161.html]</div>
<br />
<hr size="3" style="color:#000080 ;" />

<div align="center">&copy; the author, 2003. <br />Last updated: 26 May 2003</div>
<div align="center"><img src="../valid-xhtml10.gif" alt="Valid XHTML 1.0!" height="31" width="88" /></div>
<hr size="3" style="color:#000080 ;" />
<table border="0" cellpadding="5" cellspacing="10" align="center">
<tr> 
    <td><h4><a href="infres84.html">Contents</a></h4></td>
   <td align="center" valign="top"><h5 align="center"><img src="http://counter.digits.com/wc/-d/-z/6/-b/FF0033/paper161" align="middle"  width="60" height="20" border="0" hspace="4" vspace="2" alt="counter" /><br /><a href="http://www.digits.com/">Web Counter</a></h5></td>
    <td><h4><a href="../index.html">Home</a></h4></td>
  </tr>
</table>
<hr size="3" style="color:#000080 ;" />
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-672528-1";
urchinTracker();
</script>
</body>

<!-- Mirrored from informationr.net/ir/8-4/paper161.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:22 GMT -->
</html>