<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html> 

<!-- Mirrored from informationr.net/ir/9-3/paper180.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:21 GMT -->
<head>
<title>The nature of meaning in the age of Google. Google, Indexing, Web, Meaning</title>
<meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
<link href="../IRstyle.css" rel="stylesheet" />
<link rel="alternate stylesheet" type="text/css" media="screen" title="sans" href="../IRstylesans.css" />
<link rev="made" href="mailto:t.d.wilson@shef.ac.uk" />
<meta name="robots" content="all" />
<meta name="dc.title" content="The nature of meaning in the Age of Google" />
<meta name="dc.creator" content="Terrence A. Brooks" />
<meta name="dc.subject" content="Indexing, Web, Meaning" />
<meta name="dc.description" content="The culture of lay indexing has been created by the aggregation strategy employed by web search engines such as Google. Meaning is constructed in this culture by harvesting semantic content from web pages and using hyperlinks as a plebiscite for the most important web pages. The characteristic tension of the culture of lay indexing is between genuine information and spam. Google's success requires maintaining the secrecy of its parsing algorithm despite the efforts of web authors to gain advantage over the Googlebot. Legacy methods of asserting meaning such as the META keywords tag and Dublin Core are inappropriate in the lawless meaning space of the open Web. A writing guide is urged as a necessary aid for web authors who must balance enhancing expression versus the use of technologies that limit the aggregation of their work." />
<meta name="dc.publisher" content="Professor T.D. Wilson" />
<meta name="dc.coverage.placename" content="global" />
<meta name="dc.subject.keywords" content="Google, Indexing, Web, Meaning" />
<meta name="dc.subject" content="Google is the pre-eminent web search engine of our age." />
<meta content="text" name="dc.type" />
<meta name="dc.identifier" scheme="issn" content="1368-1613" />
<meta name="dc.relation.IsPartOf" content="infres92.html" />
<meta name="dc.format" content="text/html" />
<meta name="dc.language" content="en" />
<meta name="dc.rights" content="http://creativecommons.org/licenses/by-nd-nc/1.0/" />
<script language="javascript" type="text/javascript">

		var flag;
		flag = true;
		function doChangeFont()
		{
			if (flag)
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../sans.css');
			htmlDoc.appendChild(css);
			flag = false;
			} 
			else
			{
			var htmlDoc = document.getElementsByTagName('head').item(0);
			var css = document.createElement('link');
			css.setAttribute('rel', 'stylesheet');
			css.setAttribute('type', 'text/css');
			css.setAttribute('href', '../IRstyle.css');
			htmlDoc.appendChild(css);
			flag = true;
			}	
		}
		
	</script>

<style type="text/css">
#button {
	width: 45em;
	padding: 0 0 0 0;
	font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	font-size: small;
	font-weight: bold;  
	background-color: #ffffff;
	color: #000000;
	display: inline;
	text-align: center;
	}
		

#button ul {
		list-style: none;
		margin: 0;
		padding: 0;
		border: none;
		display: inline;
		}
		
#button li {
		margin: 0;
		font-family: Verdana, Lucida, Geneva, Helvetica, Arial, sans-serif;
	    font-size: small;
	    font-weight: bold;  
		background-color: #fff000<!-- #2175bc; -->
		color: #000000;
		text-decoration: none;
		display: inline;
		}

#button li a:hover {
		background-color: azure;
		color: #ff0000;
		width: auto;
		}

</style>
<style type="text/css">
<!--
.style1 {color: #FF0000}
-->
</style>
</head>
<body  bgcolor="#ffffff">
<table align="center" border="0" cellpadding="0" cellspacing="0">
<tr><td height="30" align="center" colspan="5"> <img src="../mini_logo2.gif" width="336" height="45" alt="header" /><br />
Vol. 9  No. 3, April 2004<br /><br /><div id="button">
<ul>
	<li><a href="infres93.html">Contents</a> | </li>
	<li><a href="../iraindex.html">Author index</a> | </li>
	<li><a href="../irsindex.html">Subject index</a> | </li>
	<li><a href="../search.html">Search</a> | </li>
	<li><a href="../index-2.html">Home</a></li>

</ul>
</div></td></tr>
  <tr> 
    <td>&nbsp;</td>
  </tr>
</table>
<hr style="COLOR: #000080" size="3" />

<h1>The nature of meaning in the age of Google</h1>
<h4 align="center">
<a href="mailto:tabrooks@u.washington.edu">Terrence A. Brooks</a> 
<br />Information School, The University of Washington 
<br />Seattle, WA 98195-2840, USA</h4>
<br />
<div align="center">
<input type="button" value="change font" class="btn" style="font-variant: small-caps; font-weight: bold; font-family: Verdana; color: Blue;" onclick="doChangeFont()" /></div>
<hr style="COLOR: #000080" size="1" />
<div align="center"><b>Abstract</b></div>

<blockquote>The culture of lay indexing has been created by the aggregation strategy employed by Web search engines such as Google. Meaning is constructed in this culture by harvesting semantic content from Web pages and using hyperlinks as a plebiscite for the most important Web pages. The characteristic tension of the culture of lay indexing is between genuine information and spam. Google's success requires maintaining the secrecy of its parsing algorithm despite the efforts of Web authors to gain advantage over the Googlebot. Legacy methods of asserting meaning such as the META keywords tag and Dublin Core are inappropriate in the lawless meaning space of the open Web. A writing guide is urged as a necessary aid for Web authors who must balance enhancing expression versus the use of technologies that limit the aggregation of their work.</blockquote>
<br />
<hr style="COLOR: #000080" size="1" />

<h2>The age of Google</h2>

<p>Financial markets anticipate Google's initial public stock offering to be valued at $15 billion to $25 billion (<a href="#martinuzzi">Martinuzzi, 2003</a>).  The magnitude of these figures reflects Google's pre-eminence as a Web search engine:</p>

<ul>
<li>The readers of <a href="http://searchenginewatch.com/">Search Engine Watch</a> voted Google 'Outstanding Search Service' three years in a row (<a href="#Sullivan228">Sullivan, 2003, January 28</a>).</li>
<li>Google performs the greatest number of searches per day: 250 million in February 2003 (<a href="#Sullivan225">Sullivan, 2003, February 25</a>).</li>
<li>Google dominates statistical comparisons of search engines on factors such as 'relative size', 'freshness', 'change over time' and so on (<a href="#Notess">Notess, 2003, May 28</a>).</li>
<li>'To google' has become a verb.  Google was the unanimous choice for 'Most Useful Word' for 2002 by the 
<a href="http://www.americandialect.org/woty.html">American Dialect Society</a>.</li>
</ul>

<blockquote>
&quot;I recently went to Silicon Valley to visit the offices of Google, the world's most popular search engine. It is a mind-bending experience. You can actually sit in front of a monitor and watch a sample of everything that everyone in the world is searching for. (Hint: sex, God, jobs and, oh my word, professional wrestling usually top the lists.)... In the past three years, Google has gone from processing 100 million 
searches per day to over 200 million searches per day. And get this: only one-third come from inside the U.S. The rest are in 88 other languages.&quot; (<a href="#Friedman">Friedman, 2003, June 29</a>)
</blockquote>


<h2>Google Harvests <em>Lay Indexing</em></h2>

<p>Google harvests the content placed in public Web space by millions of anonymous, independent Web authors. Google parses the text found in Web pages and uses hyperlinks among Web pages to calculate a PageRank score. The PageRank calculation includes the number of incoming to and outgoing links from a Web page, and favorably weights in-coming links from Web pages that have large PageRank scores.</p>

<blockquote>
The citation (link) graph of the Web is an important resource that has largely gone unused in existing Web search engines. We have created maps containing as many as 518 million of these hyperlinks, a significant sample of the total. These maps allow rapid calculation of a Web page's 'PageRank', an objective measure of its citation importance that corresponds well with people's subjective idea of importance. (<a href="#brin">Brin &amp; Page, 1998.</a>)
</blockquote>

<p>Probability dictates that PageRank will successfully capture the subjective sense of Web-page importance. If a large number of Web users in the role of authors create content that points at certain Web pages, then it is highly probable that those same Web pages presented as query results will satisfy a large number of Web users in the role of searchers. In other words, Google satisfies the average Web searcher so well because it has aggregated the valuations of the average Web author. In this way, Google transforms Web authors into <em>lay indexers</em> of Web content where the linkages they set 
is a plebiscite for the most 'important' Web pages.</p> 

<p>For example, a recent search for 'dogs' returned a retrieval set of more than 14.5 million Web pages with these three first:</p> 

<ol><li>I-love-dogs.com (PageRank = 6/10 on January 29, 2004),</li> 
<li>Guide dogs for the blind (PageRank = 6/10), and</li> 
<li>American Kennel Club (PageRank = 6/10)</li></ol>

<p>The combination of the PageRank of these Web pages, their use of the word 'dogs', and the hyperlink text pointing at these Web pages permits Google to bet that these are the most likely Web pages to satisfy the average Web searcher looking for 'dogs'. Google's pre-eminence as a Web search engine is clear evidence that this is a winning bet most of the time.</p>

 
<h2>Aggregating Meaning</h2>
 
<p>Google's innovation, which is worth billions, is to crawl rapidly over public Web space each month or so, and then reflect back to the Web community the words and valuations of Web content that the Web community itself has placed there.  In this way Google aggregates the meaning expressed by lay indexers in their textual Web content, their hyperlinks and hyperlink text. Utilizing hyperlink text has a distinguished pedigree: Henry Small (<a href="#small">1978</a>) suggested that citations in text act as concept symbols more than thirty years ago.</p>

<p>Aggregating meaning is possible on the Internet because there are many easily accessible semantic objects to be harvested. Analysis of the aggregations can suggest patterns of high likelihood that permit applications to recommend, adapt, profile, forecast and so on.  An aggregation strategy permits Google to suggest the most likely Website to satisfy your query, Amazon.com to suggest a likely book for purchase, and governments to collect clues about terrorists.  These are all examples of aggregating the meaning, taste, judgment, knowledge, etc., of a large universe of anonymous, independent agents to determine a common value.  In a similar fashion a stock market pools multiple buys and sells to find a price for an equity.</p>



<p>Some examples of Internet aggregator applications include: </p>

<ul>
<li><a href="http://blogdex.net/">Blogdex</a> tracks the diffusion of information through the blogosphere.

<blockquote>
Blogdex uses the links made by Webloggers as a proxy to the things they are talking about. Webloggers typically contextualize their writing with hypertext links which act as markers for the subjects they are discussing.... Blogdex crawls all of the Weblogs in its database every time they are updated and collects the links that have been made since the last time it was updated. The system then looks across all Weblogs and generates a list of fastest spreading ideas. (<a href="#blogdex">About Blogdex.</a>)
</blockquote></li>

<li><a href="http://www.biz.uiowa.edu/iem/">Iowa Electronic Markets</a> is a real-money futures market where participants can buy contracts on future economic and political events such as elections. The <a href="http://www.investorhome.com/emh.htm">efficient market hypothesis</a> suggests that market prices reflect the cumulative knowlege of large numbers of individual investors. This technique was briefly considered as a clever method of anticipating future terrorist activity, until it was found to be politically unacceptable: 

<blockquote>
'Research indicates that markets are extremely efficient, effective and timely aggregators of dispersed and even hidden information,' the Defense Department said in a statement. 'Futures markets have proven themselves to be good at predicting such things as elections results; they are often better than expert opinions.' (<a href="#hulse">Hulse, 2003, July 29.</a>)
</blockquote></li>

<li>Retailers like <a href="http://amazon.com/">Amazon.com</a> use recommender systems to personalize shopping.

<blockquote>
At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. The click-through and conversion rates&mdash;two important measures of Web-based and email advertising effectiveness&mdash;vastly exceed those of untargeted content such as banner advertisements and top-seller lists. (<a href="#linden">Linden, <em>et al.</em>, January 2003.</a>)
</blockquote></li>

<li>Specialized aggregators focus on price comparisons (<a href="#madnick">Madnick, <em><em>et al.</em></em>, 2000, October 22 </a>), news feeds (<a href="#singel">Singel, 2003, August 18</a>) and so on.

<blockquote>
On the horizon, unbeknownst to you, a new entity, whose plans are to overturn the familiar business landscape, is fast emerging.  A shopbot-like aggregator can selectively extract information from your Website, couple it with additional data from other sources including those of your competitors, and make the necessary fine tuning for intelligent comparisons. (<a href="#madnick">Madnick, <em><em>et al.</em></em>, 2000, October 22.</a>) 
</blockquote>
</li>
</ul>

<p>While semantic objects are readily available for collection on the Internet, the possibility always exists that someone has anticipated your collection and is fooling you.  In short, the convenience of surreptitiously collecting information from other people is matched by the fear that they may be manipulating your Web-bot aggregator to their advantage.  This introduces the characteristic tension between information and spam in the culture of lay indexing.</p>

<h2>Information and spam</h2>

<p>Google's most important corporate asset is its ability to collect genuine Web authorship, i.e., the Web community going about their daily lives creating content and linking to Web pages that they find useful.  <em>Bad faith</em> occurs when a Web author attempts to gain an advantage over Google, and assert his singular meaning in place of the meaning aggregated from the Web community.  A common bad faith technique is loading a Web page with words that the Googlebot will find, but are invisible to Web readers. It also includes <a href="http://www.webopedia.com/TERM/L/link_farming.html">link farming</a>, a cooperative sharing arrangement of links, and <a href="http://www.wordspy.com/words/Googlebombing.asp">Google bombing</a>, which coordinates a large number of linkages to a single page. 'Cloaking' occurs when a Web server recognizes a request from the Googlebot and responds with special content:</p>

<blockquote>
The term 'cloaking' is used to describe a Website that returns altered Webpages to search engines crawling the site. In other words, the Webserver is programmed to return different content to Google than it returns to regular users, usually in an attempt to distort search engine rankings. This can mislead users about what they'll find when they click on a search result. To preserve the accuracy and quality of our search results, Google may permanently ban from our index any sites or site authors that engage in cloaking to distort their search rankings. (<a href="http://www.google.com/Webmasters/faq.html#cloaking">Google Information for Webmasters).</a></blockquote>

<p>Unfortunately for Google and Internet aggregators in general, bad faith is attractive because it can have a big pay-off. Goldhaber's (<a href="#goldhaber">1997</a>) 'attention economy' compares the deluge of available digital information to the limited supply of human time and attention. In the attention economy, information is plentiful and human attention is scarce.  Huberman's (<a href="#huberman">2001</a>) survey indicates that 0.1% of Websites capture 32.3% of activity, indicating that the vast majority of Web content languishes in obscurity.  Therefore, a hyperlink from a stranger who has made an unforced choice to highlight your Web content has great value.  Imagine the by-passed author's chagrin at the neglect of his Web pages, and the temptation to finagle just a little bit to propel his Web pages out of the obscurity of the retrieval set of 14.5 millions to appear beside the top three Web pages for the query 'dogs'.</p>

<blockquote>Search engines are constantly adding and removing pages, as well as altering the algorithms they use to rank pages. However, there's a great obsession with Google because of the large amounts of traffic it can deliver. Of the four most popular search engines&mdash;Google, Yahoo, AOL and MSN Search&mdash;Google's results are used at the first three. (<a href="#sullivan121">Sullivan,  2003, December 1</a>).</blockquote>

<p>The controversy between Google and Daniel Brandt, author of <a href="http://www.namebase.org/nbhome.html">NameBase</a>, illustrates the obsession with Google's ability to shine the spotlight of attention and the dangers of bad faith.  If you misperceive Google to be a large Web database under the control of a system administrator, and you found your Web content indexed but ignored, you would probably conclude that you need only lobby the administrator to get the spotlight of attention to shine on your content.</p>

<blockquote>
'My problem has been to get Google to go deep enough into my site,' he says. In other words, Brandt wants Google to index the 100,000 names he has in his database, so that a Google search for 'Donald Rumsfeld' will bring up NameBase's page for the secretary of defense. (<a href="#manjoo">Manjoo, 2002</a>).
</blockquote>

<p>But Google's rankings are not the result of a systems administrator's arbitrary judgment. If Google accedes to Brandt and adjusts the valuation of the content on the NameBase Website, then it wounds itself by permitting Brandt, and not the community of lay indexers, to assert the meaning and value of the NameBase Web content. Google's concession to Brandt would lower the quality of Google's retrieval because search results would no longer reflect the average Web user, but a single individual's judgment of the value of the  NameBase Website.</p>

<p>Google's continued success depends on its ability to collect unaffected Web content, which means that it must avoid the single individual's assertion of meaning. This strategy implies that any metadata scheme for the Web that promotes the meaning assertion of a single Web author (i.e., My Web page means <em>this</em>) will be avoided by aggregators. The strategy of aggregation, the enlistment of Web authors as lay indexers, and the temptation of bad faith points to the importance of maintaining the ignorance of lay indexers.</p>

<h2>The importance of ignorance</h2>
 
 <p>Consider for a moment the various strategies Google could pursue to maximize the collection of genuine Web authorship and minimize bad faith.  Google could, for example, publicize its algorithms and then admonish everyone to behave. The Internet is, however, a network of anonymous, independent agents characterized by viruses, worms, spy ware, music piracy, identity theft, etc., that transcends national borders, invades personal privacy, abuses enterprise intranets, etc. The Internet often appears to be <em>beyond any law</em>; therefore, it would be foolish to believe that anyone would behave.  Google's only possible survival strategy is to keep its parsing and ranking algorithms absolute secrets. In short, the culture of lay indexing is one of mistrust and ignorance: The lay indexer's ignorance of when, if, and how her work will be used, and Google's mistrust of lay indexers, whom it must assume are constantly scheming to gain an advantage over the Googlebot.  For example, current interest focuses on a 'filter test' (<a href="#sullivan121">Sullivan, 2003, December 1</a>) of systematically adding and subtracting query terms in hopes of revealing Google's underlying algorithm.</p>

<blockquote>Google's order of results is automatically determined by more than 100 factors, including our PageRank algorithm.... Due to the nature of our business and our interest in protecting the integrity of our search results, this is the only information we make available to the public about our ranking system. 
(<a href="#pagerank">PageRank Information</a>).</blockquote>

<p>Compounding the lay indexer's ignorance of Google's algorithm is the unpredictable traversal of Web space.  The following table gives the 2002-2003 Googlebot monthly page requests of my own <a href="http://faculty.washington.edu/tabrooks">Website</a>.  During this two-year period, the number of my Web pages did not change dramatically, nor were there any substantial changes in Website architecture, password use, hosting server address, etc. <em>[Note: These figures combine repeated visits of the Googlebot in the same month, if any repeated visits were made.]</em></p>


<table width="60%" border="1" cellspacing="0" cellpadding="3" align="center" style="border-right: #99f5fb solid; border-top: #99f5fb solid; font-size: smaller; border-left: #99f5fb solid; border-bottom: #99f5fb solid; font-style: normal; font-family: verdana, geneva, arial, helvetica, sans-serif; background-color: #fdffdd">
<caption align="bottom"><br /><strong>Table 1: Google visits to the Brooks Website</strong></caption>
<tr>
<th>2002</th>
<th>Page Requests</th>
<th>2003</th>
<th>Page Requests</th>
 </tr>
 
 <tr>
	<td width="100">January</td>
	<td width="20">307</td>
	<td width="100">January</td>
	<td width="20">470</td>
</tr>
<tr>
	<td>February</td>
	<td>132</td>
	<td>February</td>
	<td>585</td>
</tr>
<tr>
	<td>March</td>
	<td>309</td>
    <td>March</td>
    <td>721</td>
</tr>
<tr>
	<td>April</td>
	<td>325</td>
    <td>April</td>
    <td>690</td>
</tr>
<tr>
    <td>May</td>
	<td>766</td>
	<td>May</td>
    <td>340</td>
</tr>
<tr>
	<td>June</td>
	<td>345</td>
    <td>June</td>
    <td>424</td>
</tr>
<tr>
	<td>September</td>
	<td>179</td>
    <td>September</td>
    <td>1718</td>
</tr>
 <tr>
 	<td>October</td>
	<td>695</td>
    <td>October</td>
    <td>1501</td>
</tr>
 <tr>
 	<td>November</td>
	<td>504</td>
 	<td>November</td>
	<td>1010</td>
 </tr>
 <tr>
 	<td>December</td>
	<td>528</td>
 	<td>December</td>
	<td>747</td>
 </tr>
 </table>


<p>If Google's most important corporate asset is its ability to collect unaffective Web authorship, then maintaining a lay indexing culture of absolute ignorance is the best guarantor of future success.  Web authors outraged at their helplessness might seek help from SEOs (Search Engine Optimizers) who promise to promote or manage the visibility of Websites, but Google warns of the consequences of unscrupulous activity:</p>

<blockquote>
If an SEO creates deceptive or misleading content on your behalf, such as doorway pages or 'throwaway' domains, your site could be removed entirely from Google's index. (<a href="#seo">Search Engine Optimizers</a>).</blockquote>

<p>Probably the best strategy for the average Web author is simply to construct Web pages that are as welcoming to the Googlebot as possible, and then wait patiently for the Googlebot to come by and visit them. Setting out feed for wild birds is an analogous activity.</p>

<p>Struggling to maintain the ignorance of lay indexers in the culture of lay indexing contrasts sharply with the historical treatment of indexers.  During the last several hundred years in the craft of book arts and scholarly journals, indexers have been honoured and respected. In this legacy culture of indexing, indexer ignorance was an anathema to be avoided, not enhanced.</p>

<h2>Traditional methods of constructing meaning</h2>

<p>We inherit a tradition of constructing meaning by trusting the expertise of a few. For example, the claim has been made that indexers possess a special skill for denoting the meaning of text:</p>

<blockquote>Above all, what may be called the 'index sense' is required&mdash;that is, the ability to feel instinctively, at the first glance, what and how subjects should be indexed in all their ramifications; the sense that is in touch with searchers, and appreciates just how subjects will be looked for and how to arrange so that they can most readily be found. Experience is the only school in which these qualifications can be gained. (<a href="#Nichols">Nichols, 1892: 406</a>). </blockquote>
  
<p>Meaning and trust are also implicit in database management. When the U.S. Department of Education builds a database of education resources (e.g., the ERIC database), a submission is evaluated by subject experts who select topical terms to express its meaning.</p> 
 
<blockquote>A document sent to ERIC is evaluated by subject experts (<a href="#faq">Submitting Documents to ERIC</a>)....The indexer, or abstractor/indexer, examines the document, chooses the concepts to be indexed, and translates these concepts into the indexing terminology of the system. (<a href="#processing">ERIC Processing Manual</a>).</blockquote>

<p>One reason that traditional information systems could rely on the meaning assertion of a few individuals was that these systems were devised, built and managed by information professionals.  Professionals were known, publicly accessible and held to high standards of ethics.  Information professionals, such as librarians, were considered to be operating a public trust with a view to the best interests of society.  Rare was the librarian who abused collection policy to overload a public library with books she penned herself.  Rare was the database administrator who filled a public database with his own database records.  Professionals who abused the trust given to them by society could be brought to account.</p>

<p>Another reason that traditional information systems could rely on the meaning assertion of a few individuals was that access to these systems was tightly controlled.  It was not the case that an anonymous individual could defy responsible information professionals and arbitrarily add an item to a library or database, and furthermore, independently declare its meaning:</p>

 <blockquote>
Another big difference between the Web and traditional well controlled collections is that there is virtually no control over what people can put on the Web. Couple this flexibility to publish anything with the enormous influence of search engines to route traffic and companies... deliberately manipulating search engines for profit become[s] a serious problem. This problem that has not been addressed in traditional closed information retrieval systems. (<a href="#brin">Brin &amp; Page, 1998</a>).
</blockquote>

<p>Traditional closed information systems honored the assertion of meaning by a single individual, but to succeed Google must distrust it.  This is the social consequence of a network technology that permits anyone to conflate the roles of author, indexer and publisher. That is, the Internet is an 'open' system where anyone can author anything and declare its meaning, i.e., <em>a lawless meaning space</em>.</p>

<p>A lawless meaning space is a novelty that most traditional meaning technologies have not anticipated. 
Being able to operate successfully in a lawless meaning space is, however, the key success criterion for legacy meaning technologies that are applied to Web space.</p>

<h2>Technologies for asserting meaning on the Web</h2>

<p>The notion that the Web community would cooperate to construct information objects and then share them freely is very compelling.  It echoes historical ambitions of amassing all world knowledge, e.g., the <em>World Brain</em> suggestion of H.G. Wells (<a href="#wells">1937</a>), and using associative links to create trails among pieces of information, e.g., the memex device of Vannevar Bush (<a href="#bush">1945 July</a>).  Recently the notion of a cooperating Web community has been expressed as the 'Semantic Web';:</p>

<blockquote>The Semantic Web will bring structure to the meaningful content of Web pages, creating an environment where software agents roaming from page to page can readily carry out sophisticated tasks for users....The Semantic Web is not a separate Web but an extension of the current one, in which information is given well-defined meaning, better enabling computers and people to work in cooperation.... For the semantic Web to function, computers must have access to structured collections of information and sets of inference rules that they can use to conduct automated reasoning. (<a href="#bernersLee">Berners-Lee, 2001, May 17</a>).</blockquote>

<p>At this time the Semantic Web remains more aspiration than reality, but clearly the vision would include 'software agents roaming from page to page' making determinations of meaning by using 'structured collections of information and sets of inference rules.' If structured collections of Web content mean metadata created by the author of the Web page, then this would be another example of privileging the assertion of meaning by a single individual, just what Google must avoid.  Structured metadata created by Web page authors are another form of the Daniel Brandt controversy where a single individual attempts to promote his single meaning ahead of the meaning and value given to his Web content by the Web community.  Example technologies that privilege the single assertion of meaning:</p>

<ul>
<li>The <a href="http://www.w3.org/TR/html4/struct/global.html#h-7.4.4">HTML recommendation</a> of the <a href="http://www.w3.org/">World Wide Web Consortium</a> suggests that the META element be used to specify keywords to help a search engine determine the meaning of a Web page. The recommendation offers the following example to indicate that a Web page is about vacationing in sunny Greece.<br />
		
		<pre>&lt;META name=&quot;keywords&quot; content=&quot;vacation, Greece, sunshine&quot;></pre>
		 <br />
		Since the META keywords tag is designed for a Web author to claim <em>My Web page means this</em>, it's hardly surprising that Sullivan (<a href="#sullivan320">2003, March 20</a>) reports that the keywords tag is avoided by all major search engines.</li>


<li>The <a href="http://dublincore.org/">Dublin Core</a> metadata set is designed to facilitate interoperability, i.e., the sharing of metadata across applications. It is, however, avoided by aggregators as &quot;spam&quot; (<a href="#dublin">FAQ</a>). </li> 

<li>The Resource Description Framework (RDF) 

<blockquote>...will make retrieval far faster and more accurate than it is now. Because the Web has no librarians and every Webmaster wants, above all else, to be found, we expect that RDF will achieve a typically astonishing Internet growth rate once its power becomes apparent.  (<a href="#bosak">Bosak &amp; Bray,  1999, May</a>).</blockquote>

Three years later Eberhart (<a href="#eberhart">2002, August 15</a>) reports that &quot;RDF has not caught on with a large user community.&quot; </li>
</ul>

<p>Formal metadata schemes that require cooperation and good faith to work have been applied to the Web, but remain marginal:</p>

<blockquote>A discouraging aspect of metadata usage trends on the public Web over the last five years is the seeming reluctance of content creators to adopt formal metadata schemes with which to describe their documents. For example, Dublin Core metadata appeared on only 0.5 percent of public Website home pages in 1998; that figure increased almost imperceptibly to 0.7 percent in 2002. The vast majority of metadata provided on the public Web is <em>ad hoc</em> in its creation, unstructured by any formal metadata scheme.
(<a href="#oneill">O'Neill, 2003</a>).</blockquote>

<p>Of course Google has always disdained structured metadata in the open Web as bad faith:</p>

<blockquote>Also, it is interesting to note that metadata efforts have largely failed with Web search engines, because any text on the page which is not directly represented to the user is abused to manipulate search engines. There are even numerous companies which specialize in manipulating search engines for profit. (<a href="#brin">Brin &amp; Page, 1998</a>).</blockquote>

<p>Since the Web is a lawless meaning space, you may garnish your Web pages with any sort of metadata scheme you like.  But formal metadata schemes that require cooperation and good faith of a community of Web authors will probably have a greater chance of working in 'closed' Web applications that honour the meaning assertions of single individuals, establish trust among strangers and enforce norms of application.   Examples may be corporate intranets and digital libraries.</p>


<p>Pity the poor Web author!  Condemned to a culture of ignorance and denied any direct assertion of meaning of her content!  She is encouraged to act naturally, constructing her Web content and linking to Web pages of interest.  Acting naturally, however, is not without hazard in a rapidly changing, technologically complex environment where it is easy to do something 'neat' that inadvertently makes your content unpalatable to the visiting Googlebot.  There is a fine line between using technology to jazz up your Web page and using technology that unintentionally limits the aggregation of your content.</p>


<h2>Cool tricks and feeding the Googlebot</h2>

<p>The irony of constructing content for the open Web is not knowing how aggregators will use it.  Any trick you employ to reduce your ignorance (i.e., you successfully spam the Googlebot) will be ultimately neutralized, throwing you back to the position of total ignorance:</p>

<blockquote>Google prefers developing scalable and automated solutions to problems, so we attempt to minimize hand-to-hand spam fighting. The spam reports we receive are used to create scalable algorithms that recognize and block future spam attempts.  (<a href="#google">Google Information for Webmasters</a>).
</blockquote>

<p>The SEO industry awaits for incredulous authors who do not believe that Google will protect its most precious corporate asset: our ignorance of its parsing algorithm.  It is helpful to remember that the motivation of the SEO industry is to make money.  <a href="http://www.pandia.com/optimization/index.html">Pandia SEO</a>, for example, offers a book for sale titled <em>The unfair advantage book on winning the search engine wars</em>, which warned in January 2004:</p>

<blockquote>Beware of Google's new Over-Optimization Penalty!!! ...what <em>was</em> a strategy for top positioning is now a formula for disaster. Pages that were showing in the top ten have slipped all the way down under 1000 in the rankings.  Even worse, the penalty appears to be permanent so this is a mistake to avoid at all costs. (<a href="#pandia">Planet Ocean Communications, 2004</a>).</blockquote>

<p>As an example, a SEO might suggest that you use more than four, but fewer than seven keywords in a META field.  If such a stratagem were actually to work, then it would be rapidly employed by everyone else, thus diluting its effect and throwing you back again to the position of having no special advantage. Furthermore, Google is constantly tweaking its parsing formula so you're aiming at a moving target:</p>

<blockquote>
In its latest makeover, Google also tweaked the closely guarded formula that determines which Websites are most relevant to a search request.  Google has made five significant changes to its algorithmic formulas in the past two weeks, Brin said. (<a href="#liedtke">Liedtke, 2004, February 18</a>).</blockquote>

<p>I argue the need for a survival guide for Web authors (without attempting to provide one here).  A survival guide helps someone survive, largely by avoiding hazards, as opposed to being a bag of tricks for besting someone else.  The need for a survival guide becomes compelling when you witness someone writing for the Web, but doing it in a manner that offends the Googlebot. Google has a <a href="http://www.google.com/Webmasters/guidelines.html">list of technological hazards</a> to avoid such as Javascript, cookies, session IDs, frames, DHTML and Flash. The penalty of inhibiting the Googlebot is limiting the exposure of your work. One would think that poets would be anxious to place their work before a large public, but consider the submission guidelines of <a href="http://www.poemsthatgo.com/">Poems That Go</a>:</p>

<blockquote>
Poems that Go publishes Web-specific new media, hypermedia, and electronic poetry, prose, and short narrative. We are open to all forms of multimedia, computer-generated, and interactive work that include (but are not limited to) HTML, Shockwave, Quicktime, streaming media, Flash, Java, and DHTML content. Because Poems that Go focuses on how sound, image, motion, and interactivity intersect with literary uses of the Web, we regretfully do not accept text-based poetry or written work in the traditional sense. 
(<a href="#poems">Submission guidelines</a>).
</blockquote>

<p>Such is the gulf that exists between creating cool stuff for the Web and preparing something appetizing for the Googlebot. This problem is also illustrated by the PAD project (Preservation, Archiving and Dissemination) of the  <a href="http://www.eliterature.org/">Electronic Literature Organization</a>.  PAD struggles to maintain access to classic etexts in formats such as HyperCard, Storyspace, and BZT ('Better than Zork'), a proprietary system that sold commercially for less than a year. Other classic etexts require a melange of DHTML, Flash, RealAudio, VRML, animated gifs and so on, none of which are tasty to the Googlebot.  It may be that some digital artists are willing to sacrifice exposure and wide dissemination of their work to achieve eye-popping technical effects, but I argue that the average Web author needs a survival guide to help her avoid self wounding in the pursuit of the cool.</p>

<h2>The meaning Google misses</h2>

<p>Google may index billions of Web pages, but it will never exhaust the store of meaning of the Web. The reason is that Google's aggregation strategy is only one of many different strategies that could be applied to the semantic objects in public Web space.  Hidden in the 'dogs' retrieval set of 14.5 millions are special, singular, obscure, unpopular, etc., Web pages that await a different aggregation strategy that would expose their special meanings.  To charge that Google has a bias against obscure Websites (<a href="#gerhart">Gerhart, 2004</a>), or that we suffer under a 'Googlearchy' (<a href="#hindman">Hindman, <em>et al.</em>, 2003</a>) of a few heavily linked Websites is to expect Google to be something other than Google.  Google finds the common meanings.  Many other meanings exist on the Web and await their aggregators.</p>

<h2>Acknowledgements</h2>

<p>The author wishes to acknowledge the contributions of my research assistants Karen Estlund and Sarah Bosarge, and the suggestions of the anonymous referees.</p>


<h2>References</h2>
<ul>
    
  <li><a id="bernersLee" name="bernersLee"></a>Berners-Lee, T., Hendler, J. and Lassila, O. (2001, May 17). 
  <a href="http://www.sciam.com/article.cfm?articleID=00048144-10D2-1C70-84A9809EC588EF21">The semantic Web: A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities.</a> <em>The Scientific American</em>, <strong>284</strong>(5), 34+ Retrieved 1 February, 2004 from http://www.sciam.com/article.cfm?articleID=00048144-10D2-1C70-84A9809EC588EF21</li>
  
  <li><a id="bosak" name="bosak"></a>Bosak, J. and Bray, T. (1999, May). <a href="http://www.sciam.com/article.cfm?articleID=0008C786-91DB-1CD6-B4A8809EC588EEDF">XML and the second-generation Web</a>.  <em>Scientific American</em>, <strong>280</strong>(5), 89-93 Retrieved 1 February, 2004 from http://www.sciam.com/article.cfm?articleID=0008C786-91DB-1CD6-B4A8809EC588EEDF</li>
  
  <li><a id="brin" name="brin"></a>Brin, S. and Page, L. (1998). <a href="http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm"><em>The Anatomy of a large-scale hypertextual Web search engine</em></a>. Paper delivered at the Seventh International World Wide Web Conference, Brisbane, Australia, 14-18 April, 1998. Retrieved 27 December, 2003 from http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm   </li>
  
  <li><a id="bush" name="bush"></a>Bush, V. (1945). <a href="http://www.theatlantic.com/unbound/flashbks/computer/bushf.htm">As we may think</a>. <em>The Atlantic Monthy</em>. <strong>176</strong>(1), 101-108.  Retrieved 1 February, 2004 from http://www.theatlantic.com/unbound/flashbks/computer/bushf.htm</li>

  <li><a id="dublin" name="dublin"></a>Dublin Core Metadata Initiative. (n.d.). <a href="http://dublincore.org/resources/faq/#whatsearchenginessupport">What search-engines support the Dublin Core Metadata Element Set?</a> Retrieved 6 January, 2004 from the Dublin Core Metadata Initiative Website:  http://dublincore.org/resources/faq/#whatsearchenginessupport</li> 
   
  <li><a id="eberhart" name="eberhart"></a>Eberhart, A. (2002, August 15). <a href="http://www.aifb.uni-karlsruhe.de/WBS/aeb/rdf/">Survey of RDF data on the Web</a> Retrieved 15 December, 2003 from the  Universit&auml;t Karlsruhe Website: http://www.aifb.uni-karlsruhe.de/WBS/aeb/rdf/</li>
     
  <li><a id="processing" name="processing"></a>Educational Resources Information Center (ERIC). (1997).<a href="http://www.ericfacility.net/extra/epm/indexing/indexing.html">ERIC processing manual. Chapter VII Indexing</a>. Retrieved 10 November, 2003 from the Educational Resources Information Center Website: http://www.ericfacility.net/extra/epm/indexing/indexing.html</li>

  <li><a id="faq" name="faq"></a>Educational Resources Information Center (ERIC). (n.d.). <a href="http://www.ericfacility.org/submitting.html#selection">Submitting documents to ERIC:
frequently asked questions (FAQs). What are ERIC's selection criteria?</a> Retrieved 9 September, 2003 from  the Educational Resources Information Center Website: http://www.ericfacility.org/submitting.html#selection</li>
  
  <li><a id="Friedman" name="Friedman"></a>Friedman, T.L. (2003, June 29). Is Google God?  <em>The New York Times</em>, Section 4, Page 13, Column 1</li>
  
    <li><a id="gerhart" name="gerhart"></a>Gerhart, S.L. (2004). <a href="http://firstmonday.org/issues/issue9_1/gerhart/index.html">Do Web search engines suppress controversy?</a> <em>First Monday</em>, <strong>9</strong>(1).  Retrieved 29 January, 2004 from http://firstmonday.org/issues/issue9_1/gerhart/index.html </li>
  
  <li><a id="goldhaber" name="goldhaber"></a>Goldhaber, M.H. (1997). <a href="http://www.firstmonday.dk/issues/issue2_4/goldhaber/">The attention economy and the Net.</a> <em>First Monday</em>, <strong>2</strong>(4). Retrieved 3 January, 2004 from http://www.firstmonday.dk/issues/issue2_4/goldhaber/</li>
  
  <li><a id="google" name="google"></a>Google. (2003). <a href="http://www.google.com/webmasters/guidelines.html">Google information for Webmasters: Webmaster guidelines.</a> Retrieved 24 January, 2004 from the Google Website: http://www.google.com/webmasters/guidelines.html</li>

    <li><a id="pagerank" name="pagerank"></a>Google. (2003)  <a href="http://www.google.com/webmasters/4.html">PageRank information</a>   Retrieved 23 November, 2003 from the Google Website: http://www.google.com/webmasters/4.html</li>

  <li><a id="seo" name="seo"></a>Google. (2003). <a href="http://www.google.com/webmasters/seo.html">Search engine optimizers</a>  Retrieved 23 November, 2003 from the Google Website:  http://www.google.com/webmasters/seo.html</li>

  <li><a id="hindman" name="hindman"></a>Hindman, M., Tsioutsiouliklis, K., and Johnson, J.A. (2003). <a href="http://www.princeton.edu/~mhindman/googlearchy--hindman.pdf">'Googlearchy': how a few heavily-linked sites dominate politics on the Web</a>  Retrieved 29 January, 2004 from http://www.princeton.edu/~mhindman/googlearchy--hindman.pdf</li>
  
  <li><a  id="huberman" name="huberman"></a>Huberman, B.A. (2001). <em>The laws of the Web: patterns in the ecology of information.</em>  Cambridge, MA: The MIT Press.</li>
  
  <li><a id="hulse" name="hulse"></a>Hulse, C. (2003, July 29). Pentagon prepares a futures market on terror attacks <em>The New York Times</em>, Section A, Page 1, Column 6</li>
  
  <li><a id="liedtke" name="liedtke"></a>Liedtke, M. (2004, Feburary 18). <a href="http://www.seattlepi.com/business/160997_google18.html">Google adds billion pages to Web list</a>. <em>Seattle Post_Intelligencer</em> Retrieved 24 February, 2004 from http://www.seattlepi.com/business/160997_google18.html</li>
  
 <li><a id="linden" name="linden"></a>Linden, G., Smith, B. and York, J. (2003). <a href="http://dsonline.computer.org/0301/d/wp1lind.htm">Amazon.com recommendations: item-to-item collaborative filtering</a>. <em>IEEE Distributed Systems Online</em>, <strong>4</strong>(1).  Retrieved 4 January, 2004 from http://dsonline.computer.org/0301/d/wp1lind.htm</li>
  
  <li><a id="madnick" name="madnick"></a>Madnick, S., Siegel, M., Frontini, M.A., Kemka, S., Chan, S. and Pan, H. (October 22, 2000) <a href="http://ebusiness.mit.edu/research/papers/Aggregator%20paper%2010-22-00%20SEM-v20%20FINAL.pdf"><em>Surviving and thriving in the new world of Web aggregators</em></a>. Retrieved 4 January, 2004 from the E-Commerce Research Forum Website:  http://ebusiness.mit.edu/research/papers/Aggregator%20paper%2010-22-00%20SEM-v20%20FINAL.pdf </li>
  
  <li><a id="manjoo" name="manjoo"></a>Manjoo, F. (2002, August 29). <a href="http://www.salon.com/tech/feature/2002/08/29/google_watch/index.html">Meet Mr. Anti-Google</a> <em>Salon.com</em>  Retrieved 6 January, 2004 from http://www.salon.com/tech/feature/2002/08/29/google_watch/index.html </li>
  
  <li><a id="martinuzzi" name="martinuzzi"></a>Martinuzzi, E. (2003, October 25). <a href="http://seattlepi.nwsource.com/business/145458_google25.html">Google IPO estimates company value at more than $15 billion</a>. <em>Seattle Post-Intelligencer</em>.  Retrieved 30 December, 2003 from http://seattlepi.nwsource.com/business/145458_google25.html</li>

  <li><a id="blogdex" name="blogdex"></a>Massachusetts Institute of Technology. <em>Media Laboratory</em>. (2003).<a href="http://blogdex.net/about.asp"><em>About Blogdex</em></a>  Retrieved 3 January, 2004 from the Blogdex Website: http://blogdex.net/about.asp</li>
   
  <li><a id="Nichols" name="Nichols"></a>Nichols, J.B. (1892). Indexing. <em>The Library Journal</em>, <strong>17</strong>, 406-418. </li>
  
  <li><a id="Notess" name="Notess"></a>Notess, G.R. (2003, May 28) <a href="http://www.searchengineshowdown.com/stats/">Search engine statistics</a>. Retrieved 20 November, 2003 the Search Engine Showdown Website: from http://www.searchengineshowdown.com/stats/</li>
  
   <li><a id="oneill" name="oneill"></a>O'Neill, E., Lavoie, B.F. and Bennett, R. (2003). <a href="http://www.dlib.org/dlib/april03/lavoie/04lavoie.html">Trends in the evolution of the public Web, 1998 - 2002</a> <em>D-Lib Magazine</em> <strong>9</strong>(4).  Retrieved 10 November, 2003 from http://www.dlib.org/dlib/april03/lavoie/04lavoie.html</li>
     
  <li><a id="pandia" name="pandia"></a>Planet Ocean Communications. (2004).<a href="http://www.searchenginehelp.com/pandia/">The Unfair advantage book on winning the search engine wars</a>.  Retrieved 26 January, 2004 from the Planet Ocean Communications Website: http://www.searchenginehelp.com/pandia/</li>
      
  <li><a id="singel" name="singel"></a>Singel, R. (2003, August 18). <a href="http://www.wired.com/news/infostructure/0,1377,60053,00.html">Aggregators attack info overload</a>. <em>Wired News</em> 
Retrieved 4 January, 2004 from http://www.wired.com/news/infostructure/0,1377,60053,00.html  
  </li>
  
<li><a id="small" name="small"></a>Small, H. G. (1978).  Cited documents as concept symbols  <em>Social Studies of Science</em>, <strong>8</strong>(3), 327-40.</li>
  
  <li><a id="poems" name="poems"></a>Poems That Go. (n.d.)<a href="http://www.poemsthatgo.com/guidelines.htm">Submission guidelines</a>.   Retrieved 29 January, 2004 from the Poems That Go Website http://www.poemsthatgo.com/guidelines.htm</li>
  
  <li><a id="Sullivan225" name="Sullivan225"></a>Sullivan, D. (2003, January 25). 
  <a href="http://searchenginewatch.com/reports/article.php/2156461">Searches per day</a>. <em>Search Engine Watch</em>. Retrieved 20 November, 2003 from http://searchenginewatch.com/reports/article.php/2156461.</li>
  
  <li><a id="Sullivan228" name="Sullivan228"></a>Sullivan, D. (2003, January 28). <a href="http://www.searchenginewatch.com/awards/article.php/2155921#bestsearch">2002 search engine watch awards</a>. <em>Search Engine Watch</em> Retrieved 20 November, 2003 from http://www.searchenginewatch.com/awards/article.php/2155921#bestsearch</li>
  
    <li><a id="Sullivan320" name="Sullivan320"></a>Sullivan, D. (2003, March 20). <a href="http://searchenginewatch.com/sereport/02/10-meta.html">Death of a meta tag</a> <em>Search Engine Watch</em>. Retrieved 6 January, 2003 from  http://searchenginewatch.com/sereport/02/10-meta.html </li>
  
  <li><a id="Sullivan121" name="Sullivan121"></a> Sullivan, D. (2003, December 1).  <a href="http://searchenginewatch.com/searchday/article.php/3114531">Google dance syndrome strikes again</a>.   <em>Search Engine Watch</em>. Retrieved 11 December, 2003 from http://searchenginewatch.com/searchday/article.php/3114531</li>
  
  	<li><a id="wells" name="wells"></a>Wells, H.G. (1937). <a href="http://art-bin.com/art/obrain.html">World brain: the idea of a permanent world encyclopaedia</a>.   Retrieved 4 April, 2004 from The Art Bin Website http://art-bin.com/art/obrain.html</li>
  </ul>


<hr style="COLOR: #000080" size="1" />



<table cellspacing="10" align="center">
<tr><td align="center" valign="top">
<form method="get" action="http://scholar.google.com/scholar" target="_blank">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="hidden" name="q" size="31" maxlength="255" value="&quot;search engines&quot; Google meaning" style="background-color: Yellow;" /></input> <br />
<input type="submit" name="sa" value="Scholar Search"  style="font-family: Verdana; font-weight: bold; font-size: small;" /></input>
<input type="hidden" name="num" value="100" /></input>
</td></tr></table></form>
<td style="font-size: small; font-family: Verdana, sans-serif; font-weight: bold;">Find other papers on this subject</td>
<td align="center" valign="top">
<!-- Search Google -->
<form method="get" action="http://www.google.com/custom" target="_top">
<table bgcolor="#ffffff">
<tr><td nowrap="nowrap" valign="top" align="center" height="32">
<input type="hidden" name="q" size="31" maxlength="255" value="&quot;search engines&quot; Google meaning" style="background-color: Yellow;"></input><br />
<input type="submit" name="sa" value="Google Search" style="font-family: Verdana; font-weight: bold;font-size: small" /></input>
<input type="hidden" name="client" value="pub-5081678983212084"></input>
<input type="hidden" name="forid" value="1"></input>
<input type="hidden" name="ie" value="ISO-8859-1"></input>
<input type="hidden" name="oe" value="ISO-8859-1"></input>
<input type="hidden" name="cof" value="GALT:#0066CC;GL:1;DIV:#999999;VLC:336633;AH:center;BGC:FFFFFF;LBGC:FF9900;ALC:0066CC;LC:0066CC;T:000000;GFNT:666666;GIMP:666666;FORID:1;"></input>
<input type="hidden" name="hl" value="en"></input>
</td></tr></table>
</form>
<!-- Search Google -->
</td></tr>
</table>

<hr style="COLOR: #000080" size="1" />
<div align="center">
<h4>How to cite this paper:</h4>
Brooks, T.A. (2004). &quot;The nature of meaning in the Age of Google&quot; 
&nbsp; <em>Information Research</em>, <strong>9</strong>(3) paper 180 [Available 
at http://InformationR.net/ir/9-3/paper180.html]</div>
<br />


<hr size="1" style="color:#000080 ;" />
<div align="center">Articles citing this paper, <a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=link:C3ru8vcO6WQJ:scholar.google.com/" target="_blank">according to Google Scholar</a></div>
<hr size="1" style="color:#000080 ;" />


<table align="center" cellpadding="10">
<tr><td align="center" valign="top"><div>
<img src="http://counter.digits.com/wc/-d/-z/6/-b/FF0033/paper180" align="middle"  width="60" height="20" border="0" hspace="4" vspace="2" alt="counter" /><br /><a href="http://www.digits.com/">Web Counter</a>
</div></td>


<td align="center" valign="top"><div>
&copy; the author, 2004. <br />Last updated: 3 April, 2004</div></td>

<td align="center" valign="middle"><img src="../valid-xhtml10.gif" alt="Valid XHTML 1.0!" height="16" width="44" />
</td></tr>
</table>
<hr size="1" style="color:#000080 ;" />

<table align="center"><tr><td><div id="button">
<ul>
	<li><a href="infres93.html">Contents</a> | </li>
	<li><a href="../iraindex.html">Author index</a> | </li>
	<li><a href="../irsindex.html">Subject index</a> | </li>
	<li><a href="../search.html">Search</a> | </li>
	<li><a href="../index-2.html">Home</a></li>
</ul>
</div></td></tr></table>


<hr style="COLOR: #000080" size="3" />
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-672528-1";
urchinTracker();
</script>
</body>

<!-- Mirrored from informationr.net/ir/9-3/paper180.html by HTTrack Website Copier/3.x [XR&CO'2010], Sat, 25 Dec 2010 19:11:21 GMT -->
</html>
